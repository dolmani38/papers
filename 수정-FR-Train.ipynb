{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/dolmani38/papers/blob/main/FR-Train.ipynb",
      "authorship_tag": "ABX9TyMzGecvSTnMznjVyaTtzITg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/papers/blob/main/%EC%88%98%EC%A0%95-FR-Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXOrFr6r0yu2",
        "outputId": "f046cce8-782e-485e-a53f-0decda60a5ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fr-train'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 31 (delta 9), reused 4 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (31/31), 168.32 KiB | 2.80 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yuji-roh/fr-train.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fr-train\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS5Z-hk12fGz",
        "outputId": "71f69e3c-8c54-4aca-ebbb-a671423e51f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fr-train\n",
            "/content/fr-train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FR-Train on poisoned synthetic data"
      ],
      "metadata": {
        "id": "snmmksmY26md"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "TqJv-LzZ28cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from argparse import Namespace\n",
        "\n",
        "from FRTrain_arch import Generator, DiscriminatorF, DiscriminatorR, weights_init_normal, test_model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "RarAFs2W1-Ie"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and process data (using poisoned y train label)"
      ],
      "metadata": {
        "id": "bZa7fUeo2_WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a namespace object which contains some of the hyperparameters\n",
        "opt = Namespace(num_train=2000, num_val1=200, num_val2=500, num_test=1000)"
      ],
      "metadata": {
        "id": "2ibWmCxu3ADR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = opt.num_train\n",
        "num_val1 = opt.num_val1\n",
        "num_val2 = opt.num_val2\n",
        "num_test = opt.num_test\n",
        "\n",
        "X = np.load('X_synthetic.npy') # Input features\n",
        "y = np.load('y_synthetic.npy') # Original labels\n",
        "y_poi = np.load('y_poi.npy') # Poisoned train labels\n",
        "s1 = np.load('s1_synthetic.npy') # Sensitive features\n",
        "\n",
        "X = torch.FloatTensor(X)\n",
        "y = torch.FloatTensor(y)\n",
        "y_poi = torch.FloatTensor(y_poi)\n",
        "s1 = torch.FloatTensor(s1)\n",
        "\n",
        "X_train = X[:num_train - num_val1]\n",
        "y_train = y_poi[:num_train - num_val1] # Poisoned label\n",
        "s1_train = s1[:num_train - num_val1]\n",
        "\n",
        "X_val = X[num_train: num_train + num_val1]\n",
        "y_val = y[num_train: num_train + num_val1]\n",
        "s1_val = s1[num_train: num_train + num_val1]\n",
        "\n",
        "# Currently not used\n",
        "# X_val2 = X[num_train + num_val1 : num_train + num_val1 + num_val2]\n",
        "# y_val2 = y[num_train + num_val1 : num_train + num_val1 + num_val2]\n",
        "# s1_val2 = s1[num_train + num_val1 : num_train + num_val1 + num_val2]\n",
        "\n",
        "X_test = X[num_train + num_val1 + num_val2 : num_train + num_val1 + num_val2 + num_test]\n",
        "y_test = y[num_train + num_val1 + num_val2 : num_train + num_val1 + num_val2 + num_test]\n",
        "s1_test = s1[num_train + num_val1 + num_val2 : num_train + num_val1 + num_val2 + num_test]\n",
        "\n",
        "XS_train = torch.cat([X_train, s1_train.reshape((s1_train.shape[0], 1))], dim=1)\n",
        "XS_val = torch.cat([X_val, s1_val.reshape((s1_val.shape[0], 1))], dim=1)\n",
        "XS_test = torch.cat([X_test, s1_test.reshape((s1_test.shape[0], 1))], dim=1)"
      ],
      "metadata": {
        "id": "7P-CNcD03CpC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--------------------- Number of Data -------------------------\" )\n",
        "print(\n",
        "    \"Train data : %d, Validation data : %d, Test data : %d \"\n",
        "    % (len(y_train), len(y_val), len(y_test))\n",
        ")       \n",
        "print(\"--------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWTz3SzF3Fac",
        "outputId": "aafdf0ff-61fb-4da1-d4a9-c76688a167af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------- Number of Data -------------------------\n",
            "Train data : 1800, Validation data : 200, Test data : 1000 \n",
            "--------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "quEgEfb7Ai6n",
        "outputId": "4d872aaa-f0fa-49f8-b054-7b0965b1fb92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1800, 2])\n",
            "torch.Size([1800])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(X_train)"
      ],
      "metadata": {
        "id": "IrhPjDgjQJ9R",
        "outputId": "3c1edb7a-961b-493f-d211-1e707ed25f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2b98b63910>,\n",
              " <matplotlib.lines.Line2D at 0x7f2b98b637f0>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "84WqERcGlUxs",
        "outputId": "e8a9c352-80c6-4128-ad82-938706278972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.,  1.,  1.,  ..., -1., -1., -1.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(y_train)"
      ],
      "metadata": {
        "id": "5inuhX0TRI1A",
        "outputId": "2b5245cc-5bb5-4ec9-a784-a48739a3b4fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2b0832ab80>]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(s1_train)"
      ],
      "metadata": {
        "id": "tl8HgFahQxA4",
        "outputId": "89e082e7-54d0-43c2-a2ca-abc300750a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2b9f598a90>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def make_mi_scores(X, y, discrete_features):\n",
        "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores"
      ],
      "metadata": {
        "id": "viHabPQRV-_q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = make_mi_scores(pd.DataFrame(X_train,columns=['x0','x1']), y_train, discrete_features=\"auto\")\n",
        "print(mi_scores)"
      ],
      "metadata": {
        "id": "-aOtSdysWCcB",
        "outputId": "7564ebc6-3f64-4250-d6bf-26cee5247416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x1    0.193477\n",
            "x0    0.093304\n",
            "Name: MI Scores, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = make_mi_scores(pd.DataFrame(s1_train,columns=['z0']), y_train, discrete_features=\"auto\")\n",
        "print(mi_scores)"
      ],
      "metadata": {
        "id": "FtgWshe4jSgM",
        "outputId": "8c68cce9-3d2a-4b55-b0d7-f8e4dea5983e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z0    0.010744\n",
            "Name: MI Scores, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  deep architecture  train"
      ],
      "metadata": {
        "id": "4ovTFz8xjrxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Z feature    ."
      ],
      "metadata": {
        "id": "UDG6v2Qb4La1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "yy = enc.fit_transform(y_train.reshape(-1,1)).toarray()\n",
        "yy"
      ],
      "metadata": {
        "id": "-hzLciDImKEM",
        "outputId": "9966b13b-1242-4838-d287-9575e4bb4983",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "\n",
        "from keras.models import Model   \n",
        "from keras.layers import * \n",
        "\n",
        "inputs = Input(shape=(2,)) # input tensor\n",
        "hidden1 = Dense(units=5,activation='relu')(inputs) # hidden layer 1\n",
        "outputs = Dense(units=2,activation='softmax')(hidden1) # hidden layer 1\n",
        "\n",
        "#define the model's start and end points    \n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x=X_train.numpy(), \n",
        "        y=yy, \n",
        "        epochs=1000,\n",
        "        batch_size=1000,\n",
        "        verbose=1)"
      ],
      "metadata": {
        "id": "4P6tBVwYjxn0",
        "outputId": "6f9b52c4-7234-4856-d5e1-999e85865e02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_19 (InputLayer)       [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 5)                 15        \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 2)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27\n",
            "Trainable params: 27\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "2/2 [==============================] - 1s 7ms/step - loss: 0.7294 - accuracy: 0.5272\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7253 - accuracy: 0.6433\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7213 - accuracy: 0.6444\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7173 - accuracy: 0.6472\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7135 - accuracy: 0.6467\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7097 - accuracy: 0.6489\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7060 - accuracy: 0.6511\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7025 - accuracy: 0.6528\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.6544\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.6561\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.6589\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.6594\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6860 - accuracy: 0.6611\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.6656\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6799 - accuracy: 0.6678\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6770 - accuracy: 0.6700\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6742 - accuracy: 0.6722\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6715 - accuracy: 0.6728\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6688 - accuracy: 0.6750\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6661 - accuracy: 0.6767\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6636 - accuracy: 0.6783\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6611 - accuracy: 0.6806\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6586 - accuracy: 0.6789\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6563 - accuracy: 0.6806\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6540 - accuracy: 0.6822\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6518 - accuracy: 0.6828\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6495 - accuracy: 0.6850\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6473 - accuracy: 0.6850\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6452 - accuracy: 0.6861\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6431 - accuracy: 0.6872\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.6889\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.6906\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6372 - accuracy: 0.6922\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6352 - accuracy: 0.6922\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6334 - accuracy: 0.6928\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6315 - accuracy: 0.6933\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.6928\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6280 - accuracy: 0.6939\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6262 - accuracy: 0.6956\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6245 - accuracy: 0.6961\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6229 - accuracy: 0.6967\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.6972\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6196 - accuracy: 0.6983\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6180 - accuracy: 0.7000\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6164 - accuracy: 0.7011\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6148 - accuracy: 0.7022\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.7028\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6118 - accuracy: 0.7028\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6104 - accuracy: 0.7033\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6090 - accuracy: 0.7039\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6076 - accuracy: 0.7044\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6061 - accuracy: 0.7044\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6048 - accuracy: 0.7061\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.7083\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6021 - accuracy: 0.7083\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6008 - accuracy: 0.7078\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5995 - accuracy: 0.7089\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5983 - accuracy: 0.7094\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5969 - accuracy: 0.7089\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5957 - accuracy: 0.7078\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5946 - accuracy: 0.7072\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5933 - accuracy: 0.7083\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.7089\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5910 - accuracy: 0.7094\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5899 - accuracy: 0.7089\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5887 - accuracy: 0.7083\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.7094\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5866 - accuracy: 0.7100\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5855 - accuracy: 0.7111\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5845 - accuracy: 0.7106\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5834 - accuracy: 0.7111\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5824 - accuracy: 0.7117\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5813 - accuracy: 0.7122\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5803 - accuracy: 0.7133\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5793 - accuracy: 0.7139\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5784 - accuracy: 0.7150\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5774 - accuracy: 0.7144\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.7139\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.7133\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5746 - accuracy: 0.7133\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5737 - accuracy: 0.7161\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.7161\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5719 - accuracy: 0.7183\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5710 - accuracy: 0.7194\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5702 - accuracy: 0.7211\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5693 - accuracy: 0.7217\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.7228\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5676 - accuracy: 0.7228\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5668 - accuracy: 0.7228\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5660 - accuracy: 0.7244\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5652 - accuracy: 0.7256\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5644 - accuracy: 0.7272\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5636 - accuracy: 0.7272\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5629 - accuracy: 0.7278\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5621 - accuracy: 0.7300\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5614 - accuracy: 0.7300\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7300\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5599 - accuracy: 0.7311\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5592 - accuracy: 0.7317\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5585 - accuracy: 0.7344\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5579 - accuracy: 0.7350\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5572 - accuracy: 0.7350\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5565 - accuracy: 0.7378\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5559 - accuracy: 0.7372\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5552 - accuracy: 0.7372\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5546 - accuracy: 0.7361\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5539 - accuracy: 0.7367\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7378\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.7394\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5521 - accuracy: 0.7394\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7394\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 0.7378\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5503 - accuracy: 0.7383\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5497 - accuracy: 0.7389\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5492 - accuracy: 0.7389\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5486 - accuracy: 0.7394\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.7389\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5476 - accuracy: 0.7389\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5470 - accuracy: 0.7389\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5465 - accuracy: 0.7400\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.7411\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5454 - accuracy: 0.7411\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5449 - accuracy: 0.7422\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7433\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7456\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5434 - accuracy: 0.7461\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5429 - accuracy: 0.7472\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7472\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5419 - accuracy: 0.7489\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7483\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5410 - accuracy: 0.7467\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5406 - accuracy: 0.7483\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5401 - accuracy: 0.7478\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5396 - accuracy: 0.7489\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5392 - accuracy: 0.7489\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7483\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7494\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5379 - accuracy: 0.7506\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5375 - accuracy: 0.7511\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7539\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5367 - accuracy: 0.7539\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.7539\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.7539\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7539\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7544\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.7539\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7528\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.7528\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5336 - accuracy: 0.7522\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7544\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7561\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.7567\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7578\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7572\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7578\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.7572\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7583\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.7583\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7567\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5299 - accuracy: 0.7567\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7567\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5293 - accuracy: 0.7572\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7567\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5287 - accuracy: 0.7567\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7561\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5281 - accuracy: 0.7583\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7583\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.7583\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7600\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5270 - accuracy: 0.7606\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.7606\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.7611\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5262 - accuracy: 0.7611\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7611\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7617\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5254 - accuracy: 0.7617\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7617\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.7611\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7611\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7617\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5242 - accuracy: 0.7606\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7611\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7622\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7622\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5232 - accuracy: 0.7617\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5230 - accuracy: 0.7611\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7617\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7611\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5223 - accuracy: 0.7617\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5221 - accuracy: 0.7622\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7617\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5217 - accuracy: 0.7611\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5215 - accuracy: 0.7617\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7617\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.7606\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5208 - accuracy: 0.7600\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.7611\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5204 - accuracy: 0.7611\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5202 - accuracy: 0.7622\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7628\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7628\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.7622\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.7633\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7644\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.7650\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7656\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5186 - accuracy: 0.7656\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.7656\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7656\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5180 - accuracy: 0.7661\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7661\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5176 - accuracy: 0.7661\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5174 - accuracy: 0.7661\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7661\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7656\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7644\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7650\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.7661\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5163 - accuracy: 0.7667\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5161 - accuracy: 0.7667\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5160 - accuracy: 0.7656\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7661\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7661\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.7650\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7656\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7656\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7644\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7639\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7650\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.7650\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7639\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7644\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5139 - accuracy: 0.7644\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7633\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.7633\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7639\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.7644\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7644\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.7644\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7644\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7644\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.7644\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.7644\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.7644\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5120 - accuracy: 0.7644\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7639\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.7639\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7639\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.7639\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5112 - accuracy: 0.7639\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.7639\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.7639\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.7639\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5106 - accuracy: 0.7644\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5105 - accuracy: 0.7644\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5103 - accuracy: 0.7639\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7639\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5100 - accuracy: 0.7639\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.7639\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7644\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7644\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.7644\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7644\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.7650\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5090 - accuracy: 0.7656\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7650\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5087 - accuracy: 0.7650\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5086 - accuracy: 0.7650\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7650\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7650\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5082 - accuracy: 0.7650\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.7650\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.7650\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5077 - accuracy: 0.7656\n",
            "Epoch 275/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5076 - accuracy: 0.7656\n",
            "Epoch 276/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5075 - accuracy: 0.7661\n",
            "Epoch 277/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5073 - accuracy: 0.7661\n",
            "Epoch 278/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.7661\n",
            "Epoch 279/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7667\n",
            "Epoch 280/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7672\n",
            "Epoch 281/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7672\n",
            "Epoch 282/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5066 - accuracy: 0.7678\n",
            "Epoch 283/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7694\n",
            "Epoch 284/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5063 - accuracy: 0.7694\n",
            "Epoch 285/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7694\n",
            "Epoch 286/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5060 - accuracy: 0.7694\n",
            "Epoch 287/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.7694\n",
            "Epoch 288/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.7700\n",
            "Epoch 289/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.7700\n",
            "Epoch 290/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7706\n",
            "Epoch 291/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7706\n",
            "Epoch 292/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.7706\n",
            "Epoch 293/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7706\n",
            "Epoch 294/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7711\n",
            "Epoch 295/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7711\n",
            "Epoch 296/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7706\n",
            "Epoch 297/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.7706\n",
            "Epoch 298/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5044 - accuracy: 0.7700\n",
            "Epoch 299/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7700\n",
            "Epoch 300/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5042 - accuracy: 0.7700\n",
            "Epoch 301/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.7706\n",
            "Epoch 302/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7711\n",
            "Epoch 303/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7722\n",
            "Epoch 304/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7722\n",
            "Epoch 305/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7717\n",
            "Epoch 306/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7717\n",
            "Epoch 307/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7722\n",
            "Epoch 308/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5031 - accuracy: 0.7728\n",
            "Epoch 309/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.7728\n",
            "Epoch 310/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5029 - accuracy: 0.7733\n",
            "Epoch 311/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.7739\n",
            "Epoch 312/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.7744\n",
            "Epoch 313/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7750\n",
            "Epoch 314/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5023 - accuracy: 0.7750\n",
            "Epoch 315/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7750\n",
            "Epoch 316/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5021 - accuracy: 0.7756\n",
            "Epoch 317/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5020 - accuracy: 0.7761\n",
            "Epoch 318/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5018 - accuracy: 0.7761\n",
            "Epoch 319/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.7761\n",
            "Epoch 320/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.7761\n",
            "Epoch 321/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.7756\n",
            "Epoch 322/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.7767\n",
            "Epoch 323/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7767\n",
            "Epoch 324/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.7772\n",
            "Epoch 325/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.7772\n",
            "Epoch 326/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7772\n",
            "Epoch 327/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7767\n",
            "Epoch 328/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.7761\n",
            "Epoch 329/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5004 - accuracy: 0.7767\n",
            "Epoch 330/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5003 - accuracy: 0.7772\n",
            "Epoch 331/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7778\n",
            "Epoch 332/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.7778\n",
            "Epoch 333/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.7778\n",
            "Epoch 334/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4997 - accuracy: 0.7783\n",
            "Epoch 335/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4996 - accuracy: 0.7789\n",
            "Epoch 336/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7794\n",
            "Epoch 337/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7794\n",
            "Epoch 338/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7794\n",
            "Epoch 339/1000\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.4991 - accuracy: 0.7794\n",
            "Epoch 340/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7800\n",
            "Epoch 341/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7794\n",
            "Epoch 342/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7800\n",
            "Epoch 343/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7800\n",
            "Epoch 344/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.7806\n",
            "Epoch 345/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7806\n",
            "Epoch 346/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7811\n",
            "Epoch 347/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.7817\n",
            "Epoch 348/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7811\n",
            "Epoch 349/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7811\n",
            "Epoch 350/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.7811\n",
            "Epoch 351/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.7811\n",
            "Epoch 352/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7822\n",
            "Epoch 353/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7822\n",
            "Epoch 354/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7817\n",
            "Epoch 355/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7828\n",
            "Epoch 356/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.7833\n",
            "Epoch 357/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.7833\n",
            "Epoch 358/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7833\n",
            "Epoch 359/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7828\n",
            "Epoch 360/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7828\n",
            "Epoch 361/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7828\n",
            "Epoch 362/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7828\n",
            "Epoch 363/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.7833\n",
            "Epoch 364/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7839\n",
            "Epoch 365/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4958 - accuracy: 0.7839\n",
            "Epoch 366/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7839\n",
            "Epoch 367/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7839\n",
            "Epoch 368/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7839\n",
            "Epoch 369/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7839\n",
            "Epoch 370/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7839\n",
            "Epoch 371/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7850\n",
            "Epoch 372/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7850\n",
            "Epoch 373/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.7856\n",
            "Epoch 374/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.7856\n",
            "Epoch 375/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.7856\n",
            "Epoch 376/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7861\n",
            "Epoch 377/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4944 - accuracy: 0.7861\n",
            "Epoch 378/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7861\n",
            "Epoch 379/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7867\n",
            "Epoch 380/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7867\n",
            "Epoch 381/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.7872\n",
            "Epoch 382/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7872\n",
            "Epoch 383/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7883\n",
            "Epoch 384/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7883\n",
            "Epoch 385/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7889\n",
            "Epoch 386/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7889\n",
            "Epoch 387/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7889\n",
            "Epoch 388/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.7889\n",
            "Epoch 389/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7894\n",
            "Epoch 390/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7894\n",
            "Epoch 391/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.7889\n",
            "Epoch 392/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.7900\n",
            "Epoch 393/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7900\n",
            "Epoch 394/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7894\n",
            "Epoch 395/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7894\n",
            "Epoch 396/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7894\n",
            "Epoch 397/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7900\n",
            "Epoch 398/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7900\n",
            "Epoch 399/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7900\n",
            "Epoch 400/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7906\n",
            "Epoch 401/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4916 - accuracy: 0.7906\n",
            "Epoch 402/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.7894\n",
            "Epoch 403/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.7900\n",
            "Epoch 404/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7900\n",
            "Epoch 405/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7900\n",
            "Epoch 406/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4911 - accuracy: 0.7900\n",
            "Epoch 407/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7894\n",
            "Epoch 408/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4909 - accuracy: 0.7900\n",
            "Epoch 409/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7900\n",
            "Epoch 410/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.7906\n",
            "Epoch 411/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.7900\n",
            "Epoch 412/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4904 - accuracy: 0.7900\n",
            "Epoch 413/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7900\n",
            "Epoch 414/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4902 - accuracy: 0.7894\n",
            "Epoch 415/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7894\n",
            "Epoch 416/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7894\n",
            "Epoch 417/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7894\n",
            "Epoch 418/1000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.4898 - accuracy: 0.7894\n",
            "Epoch 419/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.7900\n",
            "Epoch 420/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7906\n",
            "Epoch 421/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7906\n",
            "Epoch 422/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7906\n",
            "Epoch 423/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7911\n",
            "Epoch 424/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4891 - accuracy: 0.7917\n",
            "Epoch 425/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.7917\n",
            "Epoch 426/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7917\n",
            "Epoch 427/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4888 - accuracy: 0.7922\n",
            "Epoch 428/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7922\n",
            "Epoch 429/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7922\n",
            "Epoch 430/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4885 - accuracy: 0.7933\n",
            "Epoch 431/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.7928\n",
            "Epoch 432/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.7939\n",
            "Epoch 433/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7933\n",
            "Epoch 434/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.7939\n",
            "Epoch 435/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7944\n",
            "Epoch 436/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7944\n",
            "Epoch 437/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4878 - accuracy: 0.7939\n",
            "Epoch 438/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7939\n",
            "Epoch 439/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4876 - accuracy: 0.7939\n",
            "Epoch 440/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7939\n",
            "Epoch 441/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7939\n",
            "Epoch 442/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4873 - accuracy: 0.7933\n",
            "Epoch 443/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.7933\n",
            "Epoch 444/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7944\n",
            "Epoch 445/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4870 - accuracy: 0.7944\n",
            "Epoch 446/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7950\n",
            "Epoch 447/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7956\n",
            "Epoch 448/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7956\n",
            "Epoch 449/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.7956\n",
            "Epoch 450/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7956\n",
            "Epoch 451/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7956\n",
            "Epoch 452/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7961\n",
            "Epoch 453/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.7956\n",
            "Epoch 454/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7950\n",
            "Epoch 455/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7950\n",
            "Epoch 456/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7956\n",
            "Epoch 457/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7956\n",
            "Epoch 458/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.7956\n",
            "Epoch 459/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7967\n",
            "Epoch 460/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7967\n",
            "Epoch 461/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7967\n",
            "Epoch 462/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4852 - accuracy: 0.7967\n",
            "Epoch 463/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4851 - accuracy: 0.7967\n",
            "Epoch 464/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7967\n",
            "Epoch 465/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7967\n",
            "Epoch 466/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.7961\n",
            "Epoch 467/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7967\n",
            "Epoch 468/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7967\n",
            "Epoch 469/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7967\n",
            "Epoch 470/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7967\n",
            "Epoch 471/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.7967\n",
            "Epoch 472/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7967\n",
            "Epoch 473/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7961\n",
            "Epoch 474/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4840 - accuracy: 0.7967\n",
            "Epoch 475/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.7972\n",
            "Epoch 476/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7972\n",
            "Epoch 477/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4837 - accuracy: 0.7972\n",
            "Epoch 478/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4836 - accuracy: 0.7972\n",
            "Epoch 479/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7972\n",
            "Epoch 480/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.7972\n",
            "Epoch 481/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4833 - accuracy: 0.7972\n",
            "Epoch 482/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7972\n",
            "Epoch 483/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7972\n",
            "Epoch 484/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.7972\n",
            "Epoch 485/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7972\n",
            "Epoch 486/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.7972\n",
            "Epoch 487/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4827 - accuracy: 0.7972\n",
            "Epoch 488/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.7972\n",
            "Epoch 489/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.7967\n",
            "Epoch 490/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7972\n",
            "Epoch 491/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7978\n",
            "Epoch 492/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.7978\n",
            "Epoch 493/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7978\n",
            "Epoch 494/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.7978\n",
            "Epoch 495/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.7978\n",
            "Epoch 496/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4818 - accuracy: 0.7978\n",
            "Epoch 497/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4817 - accuracy: 0.7978\n",
            "Epoch 498/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4816 - accuracy: 0.7978\n",
            "Epoch 499/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7978\n",
            "Epoch 500/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.7978\n",
            "Epoch 501/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4813 - accuracy: 0.7978\n",
            "Epoch 502/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.7978\n",
            "Epoch 503/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4810 - accuracy: 0.7978\n",
            "Epoch 504/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7978\n",
            "Epoch 505/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7983\n",
            "Epoch 506/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.7978\n",
            "Epoch 507/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.7983\n",
            "Epoch 508/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7978\n",
            "Epoch 509/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.7978\n",
            "Epoch 510/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.7978\n",
            "Epoch 511/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.7978\n",
            "Epoch 512/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7978\n",
            "Epoch 513/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7978\n",
            "Epoch 514/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7978\n",
            "Epoch 515/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7978\n",
            "Epoch 516/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7978\n",
            "Epoch 517/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7978\n",
            "Epoch 518/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.7978\n",
            "Epoch 519/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7972\n",
            "Epoch 520/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7967\n",
            "Epoch 521/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7967\n",
            "Epoch 522/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7961\n",
            "Epoch 523/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7961\n",
            "Epoch 524/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7961\n",
            "Epoch 525/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7961\n",
            "Epoch 526/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4786 - accuracy: 0.7967\n",
            "Epoch 527/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7967\n",
            "Epoch 528/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7967\n",
            "Epoch 529/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7967\n",
            "Epoch 530/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.7972\n",
            "Epoch 531/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7978\n",
            "Epoch 532/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7978\n",
            "Epoch 533/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7978\n",
            "Epoch 534/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7978\n",
            "Epoch 535/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7978\n",
            "Epoch 536/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7978\n",
            "Epoch 537/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7978\n",
            "Epoch 538/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7983\n",
            "Epoch 539/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7983\n",
            "Epoch 540/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7983\n",
            "Epoch 541/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7983\n",
            "Epoch 542/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7978\n",
            "Epoch 543/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.7978\n",
            "Epoch 544/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7978\n",
            "Epoch 545/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7978\n",
            "Epoch 546/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7978\n",
            "Epoch 547/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.7983\n",
            "Epoch 548/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7978\n",
            "Epoch 549/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7983\n",
            "Epoch 550/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4763 - accuracy: 0.7983\n",
            "Epoch 551/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4762 - accuracy: 0.7983\n",
            "Epoch 552/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7983\n",
            "Epoch 553/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7978\n",
            "Epoch 554/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.7978\n",
            "Epoch 555/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7978\n",
            "Epoch 556/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7978\n",
            "Epoch 557/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7978\n",
            "Epoch 558/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7978\n",
            "Epoch 559/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7978\n",
            "Epoch 560/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7978\n",
            "Epoch 561/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7978\n",
            "Epoch 562/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.7978\n",
            "Epoch 563/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7978\n",
            "Epoch 564/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7978\n",
            "Epoch 565/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4749 - accuracy: 0.7978\n",
            "Epoch 566/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7983\n",
            "Epoch 567/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.7978\n",
            "Epoch 568/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7972\n",
            "Epoch 569/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7978\n",
            "Epoch 570/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7978\n",
            "Epoch 571/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7978\n",
            "Epoch 572/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7983\n",
            "Epoch 573/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7989\n",
            "Epoch 574/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7989\n",
            "Epoch 575/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7994\n",
            "Epoch 576/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7994\n",
            "Epoch 577/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7989\n",
            "Epoch 578/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7994\n",
            "Epoch 579/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7994\n",
            "Epoch 580/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.8000\n",
            "Epoch 581/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.8000\n",
            "Epoch 582/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.8000\n",
            "Epoch 583/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.8000\n",
            "Epoch 584/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7994\n",
            "Epoch 585/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.8000\n",
            "Epoch 586/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.8000\n",
            "Epoch 587/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.8006\n",
            "Epoch 588/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.8006\n",
            "Epoch 589/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.8011\n",
            "Epoch 590/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.8011\n",
            "Epoch 591/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.8006\n",
            "Epoch 592/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.8006\n",
            "Epoch 593/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.8006\n",
            "Epoch 594/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.8006\n",
            "Epoch 595/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.8006\n",
            "Epoch 596/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.8006\n",
            "Epoch 597/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.8006\n",
            "Epoch 598/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.8006\n",
            "Epoch 599/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.8000\n",
            "Epoch 600/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.8000\n",
            "Epoch 601/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.8000\n",
            "Epoch 602/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.8000\n",
            "Epoch 603/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.8006\n",
            "Epoch 604/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.8006\n",
            "Epoch 605/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4713 - accuracy: 0.8006\n",
            "Epoch 606/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.8011\n",
            "Epoch 607/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.8017\n",
            "Epoch 608/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.8022\n",
            "Epoch 609/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.8022\n",
            "Epoch 610/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.8022\n",
            "Epoch 611/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.8028\n",
            "Epoch 612/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.8028\n",
            "Epoch 613/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.8028\n",
            "Epoch 614/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.8028\n",
            "Epoch 615/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.8028\n",
            "Epoch 616/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.8028\n",
            "Epoch 617/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.8033\n",
            "Epoch 618/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.8033\n",
            "Epoch 619/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.8033\n",
            "Epoch 620/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.8033\n",
            "Epoch 621/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.8033\n",
            "Epoch 622/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.8033\n",
            "Epoch 623/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.8033\n",
            "Epoch 624/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.8033\n",
            "Epoch 625/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.8033\n",
            "Epoch 626/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.8033\n",
            "Epoch 627/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.8039\n",
            "Epoch 628/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.8039\n",
            "Epoch 629/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.8039\n",
            "Epoch 630/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.8039\n",
            "Epoch 631/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.8039\n",
            "Epoch 632/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.8039\n",
            "Epoch 633/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4689 - accuracy: 0.8039\n",
            "Epoch 634/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.8039\n",
            "Epoch 635/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.8044\n",
            "Epoch 636/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.8044\n",
            "Epoch 637/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.8044\n",
            "Epoch 638/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.8044\n",
            "Epoch 639/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.8039\n",
            "Epoch 640/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.8039\n",
            "Epoch 641/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.8039\n",
            "Epoch 642/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.8039\n",
            "Epoch 643/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.8039\n",
            "Epoch 644/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.8039\n",
            "Epoch 645/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.8039\n",
            "Epoch 646/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.8039\n",
            "Epoch 647/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.8039\n",
            "Epoch 648/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.8039\n",
            "Epoch 649/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.8033\n",
            "Epoch 650/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.8033\n",
            "Epoch 651/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.8033\n",
            "Epoch 652/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.8033\n",
            "Epoch 653/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4672 - accuracy: 0.8033\n",
            "Epoch 654/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.8033\n",
            "Epoch 655/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.8033\n",
            "Epoch 656/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.8028\n",
            "Epoch 657/1000\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4669 - accuracy: 0.8028\n",
            "Epoch 658/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.8028\n",
            "Epoch 659/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.8028\n",
            "Epoch 660/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.8028\n",
            "Epoch 661/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.8028\n",
            "Epoch 662/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.8028\n",
            "Epoch 663/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.8028\n",
            "Epoch 664/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.8028\n",
            "Epoch 665/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.8028\n",
            "Epoch 666/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.8028\n",
            "Epoch 667/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.8028\n",
            "Epoch 668/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.8028\n",
            "Epoch 669/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4659 - accuracy: 0.8028\n",
            "Epoch 670/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.8033\n",
            "Epoch 671/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.8033\n",
            "Epoch 672/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.8033\n",
            "Epoch 673/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.8033\n",
            "Epoch 674/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4655 - accuracy: 0.8039\n",
            "Epoch 675/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.8039\n",
            "Epoch 676/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.8044\n",
            "Epoch 677/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.8044\n",
            "Epoch 678/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.8044\n",
            "Epoch 679/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.8039\n",
            "Epoch 680/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.8039\n",
            "Epoch 681/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.8039\n",
            "Epoch 682/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.8039\n",
            "Epoch 683/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.8039\n",
            "Epoch 684/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.8039\n",
            "Epoch 685/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.8039\n",
            "Epoch 686/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.8039\n",
            "Epoch 687/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.8039\n",
            "Epoch 688/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.8039\n",
            "Epoch 689/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.8044\n",
            "Epoch 690/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.8044\n",
            "Epoch 691/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4642 - accuracy: 0.8044\n",
            "Epoch 692/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.8044\n",
            "Epoch 693/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.8044\n",
            "Epoch 694/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.8044\n",
            "Epoch 695/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.8056\n",
            "Epoch 696/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.8056\n",
            "Epoch 697/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.8061\n",
            "Epoch 698/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.8061\n",
            "Epoch 699/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.8061\n",
            "Epoch 700/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.8061\n",
            "Epoch 701/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.8061\n",
            "Epoch 702/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.8061\n",
            "Epoch 703/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.8067\n",
            "Epoch 704/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.8061\n",
            "Epoch 705/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.8061\n",
            "Epoch 706/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.8061\n",
            "Epoch 707/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.8061\n",
            "Epoch 708/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.8061\n",
            "Epoch 709/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.8067\n",
            "Epoch 710/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.8067\n",
            "Epoch 711/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.8067\n",
            "Epoch 712/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4625 - accuracy: 0.8067\n",
            "Epoch 713/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.8056\n",
            "Epoch 714/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.8078\n",
            "Epoch 715/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.8078\n",
            "Epoch 716/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4621 - accuracy: 0.8072\n",
            "Epoch 717/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.8072\n",
            "Epoch 718/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.8072\n",
            "Epoch 719/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.8072\n",
            "Epoch 720/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.8072\n",
            "Epoch 721/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.8072\n",
            "Epoch 722/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.8061\n",
            "Epoch 723/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.8056\n",
            "Epoch 724/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.8056\n",
            "Epoch 725/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.8061\n",
            "Epoch 726/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.8056\n",
            "Epoch 727/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.8056\n",
            "Epoch 728/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.8056\n",
            "Epoch 729/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.8056\n",
            "Epoch 730/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.8056\n",
            "Epoch 731/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.8056\n",
            "Epoch 732/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.8061\n",
            "Epoch 733/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.8061\n",
            "Epoch 734/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.8061\n",
            "Epoch 735/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.8067\n",
            "Epoch 736/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.8067\n",
            "Epoch 737/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.8072\n",
            "Epoch 738/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.8072\n",
            "Epoch 739/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.8078\n",
            "Epoch 740/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.8089\n",
            "Epoch 741/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.8089\n",
            "Epoch 742/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.8089\n",
            "Epoch 743/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.8089\n",
            "Epoch 744/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.8089\n",
            "Epoch 745/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.8094\n",
            "Epoch 746/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.8089\n",
            "Epoch 747/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.8089\n",
            "Epoch 748/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.8089\n",
            "Epoch 749/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.8089\n",
            "Epoch 750/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.8089\n",
            "Epoch 751/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.8089\n",
            "Epoch 752/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.8094\n",
            "Epoch 753/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.8094\n",
            "Epoch 754/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.8094\n",
            "Epoch 755/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.8094\n",
            "Epoch 756/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.8083\n",
            "Epoch 757/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.8078\n",
            "Epoch 758/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.8083\n",
            "Epoch 759/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.8100\n",
            "Epoch 760/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.8100\n",
            "Epoch 761/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.8100\n",
            "Epoch 762/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.8106\n",
            "Epoch 763/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.8106\n",
            "Epoch 764/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.8106\n",
            "Epoch 765/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.8106\n",
            "Epoch 766/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.8106\n",
            "Epoch 767/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.8111\n",
            "Epoch 768/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.8117\n",
            "Epoch 769/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.8117\n",
            "Epoch 770/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.8117\n",
            "Epoch 771/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.8117\n",
            "Epoch 772/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.8117\n",
            "Epoch 773/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.8111\n",
            "Epoch 774/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.8111\n",
            "Epoch 775/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.8111\n",
            "Epoch 776/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.8111\n",
            "Epoch 777/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.8111\n",
            "Epoch 778/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.8111\n",
            "Epoch 779/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.8111\n",
            "Epoch 780/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.8111\n",
            "Epoch 781/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.8111\n",
            "Epoch 782/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.8111\n",
            "Epoch 783/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4567 - accuracy: 0.8111\n",
            "Epoch 784/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.8111\n",
            "Epoch 785/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.8111\n",
            "Epoch 786/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.8111\n",
            "Epoch 787/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.8111\n",
            "Epoch 788/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.8111\n",
            "Epoch 789/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.8111\n",
            "Epoch 790/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.8111\n",
            "Epoch 791/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.8111\n",
            "Epoch 792/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.8111\n",
            "Epoch 793/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.8111\n",
            "Epoch 794/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.8106\n",
            "Epoch 795/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.8106\n",
            "Epoch 796/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.8111\n",
            "Epoch 797/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.8111\n",
            "Epoch 798/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.8111\n",
            "Epoch 799/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.8111\n",
            "Epoch 800/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.8111\n",
            "Epoch 801/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.8111\n",
            "Epoch 802/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.8111\n",
            "Epoch 803/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.8111\n",
            "Epoch 804/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.8111\n",
            "Epoch 805/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.8111\n",
            "Epoch 806/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.8111\n",
            "Epoch 807/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.8111\n",
            "Epoch 808/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.8111\n",
            "Epoch 809/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.8111\n",
            "Epoch 810/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.8106\n",
            "Epoch 811/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.8106\n",
            "Epoch 812/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.8106\n",
            "Epoch 813/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.8111\n",
            "Epoch 814/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.8111\n",
            "Epoch 815/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.8111\n",
            "Epoch 816/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.8111\n",
            "Epoch 817/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.8111\n",
            "Epoch 818/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.8111\n",
            "Epoch 819/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.8111\n",
            "Epoch 820/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.8111\n",
            "Epoch 821/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.8111\n",
            "Epoch 822/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.8111\n",
            "Epoch 823/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.8111\n",
            "Epoch 824/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.8111\n",
            "Epoch 825/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.8111\n",
            "Epoch 826/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.8111\n",
            "Epoch 827/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.8111\n",
            "Epoch 828/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.8111\n",
            "Epoch 829/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.8106\n",
            "Epoch 830/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.8106\n",
            "Epoch 831/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.8106\n",
            "Epoch 832/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.8106\n",
            "Epoch 833/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.8106\n",
            "Epoch 834/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.8106\n",
            "Epoch 835/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.8106\n",
            "Epoch 836/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.8106\n",
            "Epoch 837/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.8106\n",
            "Epoch 838/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.8106\n",
            "Epoch 839/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.8111\n",
            "Epoch 840/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.8111\n",
            "Epoch 841/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.8111\n",
            "Epoch 842/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.8111\n",
            "Epoch 843/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.8117\n",
            "Epoch 844/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.8117\n",
            "Epoch 845/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.8117\n",
            "Epoch 846/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.8117\n",
            "Epoch 847/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.8117\n",
            "Epoch 848/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.8117\n",
            "Epoch 849/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.8117\n",
            "Epoch 850/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.8117\n",
            "Epoch 851/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.8117\n",
            "Epoch 852/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.8117\n",
            "Epoch 853/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.8117\n",
            "Epoch 854/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.8117\n",
            "Epoch 855/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.8117\n",
            "Epoch 856/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.8117\n",
            "Epoch 857/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.8117\n",
            "Epoch 858/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.8117\n",
            "Epoch 859/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.8117\n",
            "Epoch 860/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.8117\n",
            "Epoch 861/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.8111\n",
            "Epoch 862/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.8111\n",
            "Epoch 863/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.8111\n",
            "Epoch 864/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.8111\n",
            "Epoch 865/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.8111\n",
            "Epoch 866/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.8111\n",
            "Epoch 867/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.8111\n",
            "Epoch 868/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.8111\n",
            "Epoch 869/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.8111\n",
            "Epoch 870/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.8111\n",
            "Epoch 871/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8111\n",
            "Epoch 872/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8106\n",
            "Epoch 873/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.8106\n",
            "Epoch 874/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.8111\n",
            "Epoch 875/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.8111\n",
            "Epoch 876/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.8111\n",
            "Epoch 877/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.8111\n",
            "Epoch 878/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.8111\n",
            "Epoch 879/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.8117\n",
            "Epoch 880/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.8117\n",
            "Epoch 881/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.8117\n",
            "Epoch 882/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.8111\n",
            "Epoch 883/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.8111\n",
            "Epoch 884/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.8117\n",
            "Epoch 885/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.8117\n",
            "Epoch 886/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.8117\n",
            "Epoch 887/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.8117\n",
            "Epoch 888/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.8117\n",
            "Epoch 889/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.8111\n",
            "Epoch 890/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.8111\n",
            "Epoch 891/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.8111\n",
            "Epoch 892/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.8111\n",
            "Epoch 893/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.8111\n",
            "Epoch 894/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.8111\n",
            "Epoch 895/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.8106\n",
            "Epoch 896/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.8106\n",
            "Epoch 897/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.8106\n",
            "Epoch 898/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.8106\n",
            "Epoch 899/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.8106\n",
            "Epoch 900/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8106\n",
            "Epoch 901/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.8106\n",
            "Epoch 902/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.8106\n",
            "Epoch 903/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.8106\n",
            "Epoch 904/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.8106\n",
            "Epoch 905/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.8106\n",
            "Epoch 906/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.8106\n",
            "Epoch 907/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.8111\n",
            "Epoch 908/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.8111\n",
            "Epoch 909/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.8111\n",
            "Epoch 910/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.8111\n",
            "Epoch 911/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.8111\n",
            "Epoch 912/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.8111\n",
            "Epoch 913/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.8111\n",
            "Epoch 914/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.8111\n",
            "Epoch 915/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.8111\n",
            "Epoch 916/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.8117\n",
            "Epoch 917/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.8111\n",
            "Epoch 918/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.8111\n",
            "Epoch 919/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.8111\n",
            "Epoch 920/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.8122\n",
            "Epoch 921/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.8122\n",
            "Epoch 922/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.8122\n",
            "Epoch 923/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.8122\n",
            "Epoch 924/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.8122\n",
            "Epoch 925/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.8122\n",
            "Epoch 926/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.8122\n",
            "Epoch 927/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.8122\n",
            "Epoch 928/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.8117\n",
            "Epoch 929/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.8117\n",
            "Epoch 930/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.8117\n",
            "Epoch 931/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.8111\n",
            "Epoch 932/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.8111\n",
            "Epoch 933/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.8111\n",
            "Epoch 934/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.8117\n",
            "Epoch 935/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.8111\n",
            "Epoch 936/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.8117\n",
            "Epoch 937/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.8117\n",
            "Epoch 938/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.8106\n",
            "Epoch 939/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.8111\n",
            "Epoch 940/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.8111\n",
            "Epoch 941/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.8106\n",
            "Epoch 942/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.8117\n",
            "Epoch 943/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.8117\n",
            "Epoch 944/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.8117\n",
            "Epoch 945/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.8117\n",
            "Epoch 946/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.8117\n",
            "Epoch 947/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.8117\n",
            "Epoch 948/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.8117\n",
            "Epoch 949/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.8117\n",
            "Epoch 950/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.8111\n",
            "Epoch 951/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.8111\n",
            "Epoch 952/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.8111\n",
            "Epoch 953/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.8111\n",
            "Epoch 954/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.8111\n",
            "Epoch 955/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.8117\n",
            "Epoch 956/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.8117\n",
            "Epoch 957/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.8117\n",
            "Epoch 958/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.8117\n",
            "Epoch 959/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.8117\n",
            "Epoch 960/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.8117\n",
            "Epoch 961/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.8117\n",
            "Epoch 962/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.8117\n",
            "Epoch 963/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.8117\n",
            "Epoch 964/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.8117\n",
            "Epoch 965/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.8111\n",
            "Epoch 966/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8111\n",
            "Epoch 967/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.8111\n",
            "Epoch 968/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.8111\n",
            "Epoch 969/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.8117\n",
            "Epoch 970/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.8117\n",
            "Epoch 971/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.8117\n",
            "Epoch 972/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.8117\n",
            "Epoch 973/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.8117\n",
            "Epoch 974/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.8106\n",
            "Epoch 975/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8106\n",
            "Epoch 976/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8117\n",
            "Epoch 977/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.8117\n",
            "Epoch 978/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.8106\n",
            "Epoch 979/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.8111\n",
            "Epoch 980/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.8111\n",
            "Epoch 981/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.8111\n",
            "Epoch 982/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.8117\n",
            "Epoch 983/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.8117\n",
            "Epoch 984/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.8117\n",
            "Epoch 985/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.8117\n",
            "Epoch 986/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.8117\n",
            "Epoch 987/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.8117\n",
            "Epoch 988/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.8117\n",
            "Epoch 989/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.8117\n",
            "Epoch 990/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.8117\n",
            "Epoch 991/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.8117\n",
            "Epoch 992/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.8117\n",
            "Epoch 993/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.8117\n",
            "Epoch 994/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.8111\n",
            "Epoch 995/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.8117\n",
            "Epoch 996/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.8122\n",
            "Epoch 997/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.8117\n",
            "Epoch 998/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.8117\n",
            "Epoch 999/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.8117\n",
            "Epoch 1000/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.8117\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2a7c199a90>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predicted_y = model.predict(X_test.numpy())\n",
        "predicted_yy = (predicted_y > 0.5) * 1\n",
        "print('accuracy_score',accuracy_score(enc.transform(y_test.reshape(-1,1)).toarray(),predicted_yy)*100)\n",
        "print('classification_report\\n',classification_report(enc.transform(y_test.reshape(-1,1)).toarray(),predicted_yy))"
      ],
      "metadata": {
        "id": "jUPac28Qs_dA",
        "outputId": "61bc6f7e-4aeb-4506-88ad-326c9d6d28ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 1ms/step\n",
            "accuracy_score 80.9\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.89      0.82       481\n",
            "           1       0.88      0.73      0.80       519\n",
            "\n",
            "   micro avg       0.81      0.81      0.81      1000\n",
            "   macro avg       0.82      0.81      0.81      1000\n",
            "weighted avg       0.82      0.81      0.81      1000\n",
            " samples avg       0.81      0.81      0.81      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Disparate Impact metric\n",
        "\n",
        "+ Disparate : \n",
        "+ https://www.giskard.ai/knowledge/how-to-test-ml-models-5-the-80-rule-to-measure-disparity\n",
        "+ The proportion of a protected (minority) group with respect to an unprotected (majority) one, given a positive outcome, should be more than 80%.\n",
        "+ The ratio of positive outcome probabilities, an AI model predicts, given the protected subset over the rest (unprotected) subset should be more than 80%.\n",
        "+ Mathematically, we can formulate it as:\n",
        "\n",
        "$$\n",
        "DI = \\frac{p(y=1|D=protected)}{p(y=1|D=unprotected)}\n",
        "$$\n",
        "\n",
        "+  , unprotected (majority) = , ,  protected (minority) =  , \n",
        "+ p(|) / p(|) > 0.80   .\n",
        "+ p(|) / p(|) > 0.80\n",
        "+    1 (100%)  , 0.8   fair    !\n"
      ],
      "metadata": {
        "id": "ePW5WkKrsK-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "s1 = s1_enc.fit_transform(s1_train.reshape(-1,1)).toarray()\n",
        "print(s1)\n",
        "enc_s1_test = s1_enc.transform(s1_test.reshape(-1,1)).toarray()\n",
        "enc_s1_test"
      ],
      "metadata": {
        "id": "OQBtarXDsKPt",
        "outputId": "396afe49-3e36-4c0e-9ef5-c8e9b453678b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pr_y_hat_1_z_0 = sum(predicted_yy[[i for i, x in enumerate(enc_s1_test[:,0]==0) if x],0]==1)\n",
        "Pr_y_hat_1_z_1 = sum(predicted_yy[[i for i, x in enumerate(enc_s1_test[:,0]==1) if x],0]==1)\n",
        "print('Pr_y_hat_1_z_0',Pr_y_hat_1_z_0)\n",
        "print('Pr_y_hat_1_z_1',Pr_y_hat_1_z_1)"
      ],
      "metadata": {
        "id": "RtRJi01l3Apk",
        "outputId": "5184edc5-7471-445e-b00b-fd40ba61d2e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pr_y_hat_1_z_0 176\n",
            "Pr_y_hat_1_z_1 392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('s1_test 1 ',sum(enc_s1_test[:,0]==1), ' predicted_y 1 ',Pr_y_hat_1_z_1)\n",
        "print('s1_test 0 ',sum(enc_s1_test[:,0]==0), ' predicted_y 1 ',Pr_y_hat_1_z_0)"
      ],
      "metadata": {
        "id": "29SwJKTav2ss",
        "outputId": "eec3a7f1-acc8-4d77-ba74-e726f4936a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s1_test 1  573  predicted_y 1  392\n",
            "s1_test 0  427  predicted_y 1  176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DI = min(Pr_y_hat_1_z_0, Pr_y_hat_1_z_1) / max(Pr_y_hat_1_z_0, Pr_y_hat_1_z_1)\n",
        "print('Disparate Impact', DI)"
      ],
      "metadata": {
        "id": "SaSfuaFZ0Hqq",
        "outputId": "cd7ebfea-78b7-438f-f4c8-3bcfa852d782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate Impact 0.4489795918367347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Z feature   ."
      ],
      "metadata": {
        "id": "iSsVyI184a4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "\n",
        "from keras.models import Model   \n",
        "from keras.layers import * \n",
        "\n",
        "inputs = Input(shape=(3,)) # input tensor -> Z , 3 feature .\n",
        "hidden1 = Dense(units=5,activation='relu')(inputs) # hidden layer 1\n",
        "outputs = Dense(units=2,activation='softmax')(hidden1) # hidden layer 1\n",
        "\n",
        "#define the model's start and end points    \n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x=np.concatenate((X_train.numpy(),s1_train.reshape(-1,1).numpy()),axis=1), \n",
        "        y=yy, \n",
        "        epochs=1000,\n",
        "        batch_size=1000,\n",
        "        verbose=1)"
      ],
      "metadata": {
        "id": "B6EfTApZ4enu",
        "outputId": "317e0f55-6720-46f0-f521-d1cc369fe6b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 3)]               0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 5)                 20        \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 2)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32\n",
            "Trainable params: 32\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 0.7689 - accuracy: 0.4089\n",
            "Epoch 2/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7632 - accuracy: 0.5206\n",
            "Epoch 3/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7575 - accuracy: 0.5333\n",
            "Epoch 4/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7518 - accuracy: 0.5456\n",
            "Epoch 5/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7463 - accuracy: 0.4539\n",
            "Epoch 6/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7406 - accuracy: 0.4606\n",
            "Epoch 7/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7352 - accuracy: 0.4644\n",
            "Epoch 8/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7299 - accuracy: 0.4728\n",
            "Epoch 9/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7246 - accuracy: 0.4811\n",
            "Epoch 10/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7194 - accuracy: 0.4844\n",
            "Epoch 11/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7143 - accuracy: 0.4894\n",
            "Epoch 12/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7092 - accuracy: 0.5572\n",
            "Epoch 13/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7043 - accuracy: 0.6233\n",
            "Epoch 14/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6994 - accuracy: 0.6372\n",
            "Epoch 15/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.6511\n",
            "Epoch 16/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6901 - accuracy: 0.6589\n",
            "Epoch 17/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6856 - accuracy: 0.6700\n",
            "Epoch 18/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.6739\n",
            "Epoch 19/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.6783\n",
            "Epoch 20/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6724 - accuracy: 0.6806\n",
            "Epoch 21/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6684 - accuracy: 0.6833\n",
            "Epoch 22/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6644 - accuracy: 0.6872\n",
            "Epoch 23/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6605 - accuracy: 0.6917\n",
            "Epoch 24/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6567 - accuracy: 0.6933\n",
            "Epoch 25/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6531 - accuracy: 0.6978\n",
            "Epoch 26/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6493 - accuracy: 0.6978\n",
            "Epoch 27/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6459 - accuracy: 0.6989\n",
            "Epoch 28/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6426 - accuracy: 0.6994\n",
            "Epoch 29/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6392 - accuracy: 0.7000\n",
            "Epoch 30/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6361 - accuracy: 0.7011\n",
            "Epoch 31/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6330 - accuracy: 0.7017\n",
            "Epoch 32/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6300 - accuracy: 0.7011\n",
            "Epoch 33/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.7028\n",
            "Epoch 34/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6243 - accuracy: 0.7017\n",
            "Epoch 35/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6217 - accuracy: 0.7017\n",
            "Epoch 36/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6191 - accuracy: 0.7006\n",
            "Epoch 37/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6165 - accuracy: 0.7022\n",
            "Epoch 38/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6141 - accuracy: 0.7039\n",
            "Epoch 39/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6117 - accuracy: 0.7078\n",
            "Epoch 40/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6095 - accuracy: 0.7083\n",
            "Epoch 41/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6073 - accuracy: 0.7117\n",
            "Epoch 42/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6052 - accuracy: 0.7139\n",
            "Epoch 43/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6031 - accuracy: 0.7144\n",
            "Epoch 44/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6012 - accuracy: 0.7167\n",
            "Epoch 45/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5992 - accuracy: 0.7178\n",
            "Epoch 46/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.7189\n",
            "Epoch 47/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.7194\n",
            "Epoch 48/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.7183\n",
            "Epoch 49/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.7211\n",
            "Epoch 50/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5906 - accuracy: 0.7200\n",
            "Epoch 51/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5890 - accuracy: 0.7217\n",
            "Epoch 52/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5875 - accuracy: 0.7217\n",
            "Epoch 53/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.7222\n",
            "Epoch 54/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5846 - accuracy: 0.7211\n",
            "Epoch 55/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5833 - accuracy: 0.7217\n",
            "Epoch 56/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5819 - accuracy: 0.7222\n",
            "Epoch 57/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.7228\n",
            "Epoch 58/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5795 - accuracy: 0.7233\n",
            "Epoch 59/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5782 - accuracy: 0.7239\n",
            "Epoch 60/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.7239\n",
            "Epoch 61/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5759 - accuracy: 0.7250\n",
            "Epoch 62/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5748 - accuracy: 0.7261\n",
            "Epoch 63/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5738 - accuracy: 0.7267\n",
            "Epoch 64/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5727 - accuracy: 0.7278\n",
            "Epoch 65/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5717 - accuracy: 0.7289\n",
            "Epoch 66/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.7317\n",
            "Epoch 67/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5698 - accuracy: 0.7317\n",
            "Epoch 68/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5688 - accuracy: 0.7328\n",
            "Epoch 69/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5679 - accuracy: 0.7350\n",
            "Epoch 70/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5670 - accuracy: 0.7378\n",
            "Epoch 71/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.7389\n",
            "Epoch 72/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5653 - accuracy: 0.7400\n",
            "Epoch 73/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5645 - accuracy: 0.7439\n",
            "Epoch 74/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5637 - accuracy: 0.7461\n",
            "Epoch 75/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5629 - accuracy: 0.7467\n",
            "Epoch 76/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5621 - accuracy: 0.7478\n",
            "Epoch 77/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5614 - accuracy: 0.7478\n",
            "Epoch 78/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7500\n",
            "Epoch 79/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5600 - accuracy: 0.7511\n",
            "Epoch 80/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5593 - accuracy: 0.7517\n",
            "Epoch 81/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5586 - accuracy: 0.7522\n",
            "Epoch 82/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5579 - accuracy: 0.7528\n",
            "Epoch 83/1000\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5573 - accuracy: 0.7533\n",
            "Epoch 84/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7533\n",
            "Epoch 85/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5561 - accuracy: 0.7556\n",
            "Epoch 86/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.7556\n",
            "Epoch 87/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7556\n",
            "Epoch 88/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7556\n",
            "Epoch 89/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7556\n",
            "Epoch 90/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5531 - accuracy: 0.7556\n",
            "Epoch 91/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5526 - accuracy: 0.7561\n",
            "Epoch 92/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5521 - accuracy: 0.7561\n",
            "Epoch 93/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7561\n",
            "Epoch 94/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.7561\n",
            "Epoch 95/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5505 - accuracy: 0.7561\n",
            "Epoch 96/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5500 - accuracy: 0.7556\n",
            "Epoch 97/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5495 - accuracy: 0.7567\n",
            "Epoch 98/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7567\n",
            "Epoch 99/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5485 - accuracy: 0.7567\n",
            "Epoch 100/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5480 - accuracy: 0.7567\n",
            "Epoch 101/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5476 - accuracy: 0.7572\n",
            "Epoch 102/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.7578\n",
            "Epoch 103/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5467 - accuracy: 0.7589\n",
            "Epoch 104/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5462 - accuracy: 0.7594\n",
            "Epoch 105/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5458 - accuracy: 0.7594\n",
            "Epoch 106/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5454 - accuracy: 0.7594\n",
            "Epoch 107/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7594\n",
            "Epoch 108/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5445 - accuracy: 0.7589\n",
            "Epoch 109/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5441 - accuracy: 0.7594\n",
            "Epoch 110/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5437 - accuracy: 0.7594\n",
            "Epoch 111/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7589\n",
            "Epoch 112/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5429 - accuracy: 0.7600\n",
            "Epoch 113/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7600\n",
            "Epoch 114/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7600\n",
            "Epoch 115/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7594\n",
            "Epoch 116/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5414 - accuracy: 0.7606\n",
            "Epoch 117/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5410 - accuracy: 0.7611\n",
            "Epoch 118/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5406 - accuracy: 0.7611\n",
            "Epoch 119/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7622\n",
            "Epoch 120/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5399 - accuracy: 0.7622\n",
            "Epoch 121/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7633\n",
            "Epoch 122/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7633\n",
            "Epoch 123/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7644\n",
            "Epoch 124/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7650\n",
            "Epoch 125/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7650\n",
            "Epoch 126/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5378 - accuracy: 0.7656\n",
            "Epoch 127/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5375 - accuracy: 0.7656\n",
            "Epoch 128/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.7650\n",
            "Epoch 129/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.7650\n",
            "Epoch 130/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.7644\n",
            "Epoch 131/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7644\n",
            "Epoch 132/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.7639\n",
            "Epoch 133/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5356 - accuracy: 0.7644\n",
            "Epoch 134/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7650\n",
            "Epoch 135/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7644\n",
            "Epoch 136/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7650\n",
            "Epoch 137/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.7656\n",
            "Epoch 138/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.7656\n",
            "Epoch 139/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5337 - accuracy: 0.7650\n",
            "Epoch 140/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7650\n",
            "Epoch 141/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7650\n",
            "Epoch 142/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7650\n",
            "Epoch 143/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7650\n",
            "Epoch 144/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5323 - accuracy: 0.7656\n",
            "Epoch 145/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5320 - accuracy: 0.7661\n",
            "Epoch 146/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7661\n",
            "Epoch 147/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5315 - accuracy: 0.7678\n",
            "Epoch 148/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7683\n",
            "Epoch 149/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7678\n",
            "Epoch 150/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.7678\n",
            "Epoch 151/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5304 - accuracy: 0.7683\n",
            "Epoch 152/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5301 - accuracy: 0.7683\n",
            "Epoch 153/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7689\n",
            "Epoch 154/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.7689\n",
            "Epoch 155/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5293 - accuracy: 0.7689\n",
            "Epoch 156/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7694\n",
            "Epoch 157/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.7700\n",
            "Epoch 158/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7711\n",
            "Epoch 159/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5283 - accuracy: 0.7717\n",
            "Epoch 160/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5280 - accuracy: 0.7717\n",
            "Epoch 161/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7722\n",
            "Epoch 162/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7722\n",
            "Epoch 163/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7722\n",
            "Epoch 164/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7722\n",
            "Epoch 165/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7722\n",
            "Epoch 166/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5266 - accuracy: 0.7722\n",
            "Epoch 167/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5264 - accuracy: 0.7722\n",
            "Epoch 168/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5262 - accuracy: 0.7722\n",
            "Epoch 169/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7717\n",
            "Epoch 170/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7717\n",
            "Epoch 171/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7717\n",
            "Epoch 172/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7717\n",
            "Epoch 173/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5250 - accuracy: 0.7711\n",
            "Epoch 174/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7711\n",
            "Epoch 175/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.7717\n",
            "Epoch 176/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7717\n",
            "Epoch 177/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5242 - accuracy: 0.7717\n",
            "Epoch 178/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7717\n",
            "Epoch 179/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.7728\n",
            "Epoch 180/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.7728\n",
            "Epoch 181/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5234 - accuracy: 0.7728\n",
            "Epoch 182/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7728\n",
            "Epoch 183/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7739\n",
            "Epoch 184/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5228 - accuracy: 0.7744\n",
            "Epoch 185/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7744\n",
            "Epoch 186/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5224 - accuracy: 0.7744\n",
            "Epoch 187/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7744\n",
            "Epoch 188/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5220 - accuracy: 0.7750\n",
            "Epoch 189/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7744\n",
            "Epoch 190/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.7744\n",
            "Epoch 191/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.7744\n",
            "Epoch 192/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7744\n",
            "Epoch 193/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.7744\n",
            "Epoch 194/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7744\n",
            "Epoch 195/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5207 - accuracy: 0.7744\n",
            "Epoch 196/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7744\n",
            "Epoch 197/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7744\n",
            "Epoch 198/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5202 - accuracy: 0.7744\n",
            "Epoch 199/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7744\n",
            "Epoch 200/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7744\n",
            "Epoch 201/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7744\n",
            "Epoch 202/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.7744\n",
            "Epoch 203/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5193 - accuracy: 0.7744\n",
            "Epoch 204/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7750\n",
            "Epoch 205/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5190 - accuracy: 0.7744\n",
            "Epoch 206/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7744\n",
            "Epoch 207/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5186 - accuracy: 0.7728\n",
            "Epoch 208/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.7722\n",
            "Epoch 209/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7728\n",
            "Epoch 210/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7728\n",
            "Epoch 211/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5180 - accuracy: 0.7728\n",
            "Epoch 212/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7728\n",
            "Epoch 213/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.7728\n",
            "Epoch 214/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5175 - accuracy: 0.7728\n",
            "Epoch 215/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.7728\n",
            "Epoch 216/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7728\n",
            "Epoch 217/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7722\n",
            "Epoch 218/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7722\n",
            "Epoch 219/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7722\n",
            "Epoch 220/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7728\n",
            "Epoch 221/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7728\n",
            "Epoch 222/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5163 - accuracy: 0.7728\n",
            "Epoch 223/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5161 - accuracy: 0.7722\n",
            "Epoch 224/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5160 - accuracy: 0.7722\n",
            "Epoch 225/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5158 - accuracy: 0.7728\n",
            "Epoch 226/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5157 - accuracy: 0.7733\n",
            "Epoch 227/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7733\n",
            "Epoch 228/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.7733\n",
            "Epoch 229/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7733\n",
            "Epoch 230/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7733\n",
            "Epoch 231/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7733\n",
            "Epoch 232/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7739\n",
            "Epoch 233/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7744\n",
            "Epoch 234/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7744\n",
            "Epoch 235/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7744\n",
            "Epoch 236/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7744\n",
            "Epoch 237/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7744\n",
            "Epoch 238/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7744\n",
            "Epoch 239/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7744\n",
            "Epoch 240/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.7744\n",
            "Epoch 241/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7744\n",
            "Epoch 242/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7744\n",
            "Epoch 243/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5134 - accuracy: 0.7744\n",
            "Epoch 244/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.7744\n",
            "Epoch 245/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7744\n",
            "Epoch 246/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7739\n",
            "Epoch 247/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.7739\n",
            "Epoch 248/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7739\n",
            "Epoch 249/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.7739\n",
            "Epoch 250/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7739\n",
            "Epoch 251/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.7739\n",
            "Epoch 252/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5123 - accuracy: 0.7733\n",
            "Epoch 253/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.7733\n",
            "Epoch 254/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.7733\n",
            "Epoch 255/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5120 - accuracy: 0.7733\n",
            "Epoch 256/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7728\n",
            "Epoch 257/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7728\n",
            "Epoch 258/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7728\n",
            "Epoch 259/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5115 - accuracy: 0.7728\n",
            "Epoch 260/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.7733\n",
            "Epoch 261/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7733\n",
            "Epoch 262/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.7733\n",
            "Epoch 263/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.7728\n",
            "Epoch 264/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5110 - accuracy: 0.7728\n",
            "Epoch 265/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.7733\n",
            "Epoch 266/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.7733\n",
            "Epoch 267/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5107 - accuracy: 0.7733\n",
            "Epoch 268/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.7733\n",
            "Epoch 269/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7728\n",
            "Epoch 270/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.7733\n",
            "Epoch 271/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5103 - accuracy: 0.7733\n",
            "Epoch 272/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.7739\n",
            "Epoch 273/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.7733\n",
            "Epoch 274/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.7728\n",
            "Epoch 275/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.7728\n",
            "Epoch 276/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7728\n",
            "Epoch 277/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5097 - accuracy: 0.7728\n",
            "Epoch 278/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7728\n",
            "Epoch 279/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.7733\n",
            "Epoch 280/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5094 - accuracy: 0.7733\n",
            "Epoch 281/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5093 - accuracy: 0.7733\n",
            "Epoch 282/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.7733\n",
            "Epoch 283/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.7744\n",
            "Epoch 284/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.7744\n",
            "Epoch 285/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.7739\n",
            "Epoch 286/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7739\n",
            "Epoch 287/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.7739\n",
            "Epoch 288/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5087 - accuracy: 0.7739\n",
            "Epoch 289/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5086 - accuracy: 0.7744\n",
            "Epoch 290/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7744\n",
            "Epoch 291/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.7744\n",
            "Epoch 292/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.7750\n",
            "Epoch 293/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7750\n",
            "Epoch 294/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7750\n",
            "Epoch 295/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5081 - accuracy: 0.7756\n",
            "Epoch 296/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.7756\n",
            "Epoch 297/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.7756\n",
            "Epoch 298/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.7756\n",
            "Epoch 299/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.7756\n",
            "Epoch 300/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7756\n",
            "Epoch 301/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5076 - accuracy: 0.7756\n",
            "Epoch 302/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7761\n",
            "Epoch 303/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7761\n",
            "Epoch 304/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7767\n",
            "Epoch 305/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5073 - accuracy: 0.7772\n",
            "Epoch 306/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.7772\n",
            "Epoch 307/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5071 - accuracy: 0.7772\n",
            "Epoch 308/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5071 - accuracy: 0.7772\n",
            "Epoch 309/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7772\n",
            "Epoch 310/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7772\n",
            "Epoch 311/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7772\n",
            "Epoch 312/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7772\n",
            "Epoch 313/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5067 - accuracy: 0.7772\n",
            "Epoch 314/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5066 - accuracy: 0.7772\n",
            "Epoch 315/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7778\n",
            "Epoch 316/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7778\n",
            "Epoch 317/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7778\n",
            "Epoch 318/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5063 - accuracy: 0.7778\n",
            "Epoch 319/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7778\n",
            "Epoch 320/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7767\n",
            "Epoch 321/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5061 - accuracy: 0.7767\n",
            "Epoch 322/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5060 - accuracy: 0.7756\n",
            "Epoch 323/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5060 - accuracy: 0.7750\n",
            "Epoch 324/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.7750\n",
            "Epoch 325/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7750\n",
            "Epoch 326/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7750\n",
            "Epoch 327/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.7750\n",
            "Epoch 328/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.7750\n",
            "Epoch 329/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7750\n",
            "Epoch 330/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7750\n",
            "Epoch 331/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7750\n",
            "Epoch 332/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7750\n",
            "Epoch 333/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5053 - accuracy: 0.7750\n",
            "Epoch 334/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7750\n",
            "Epoch 335/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7750\n",
            "Epoch 336/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.7750\n",
            "Epoch 337/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7750\n",
            "Epoch 338/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7750\n",
            "Epoch 339/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5049 - accuracy: 0.7750\n",
            "Epoch 340/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7750\n",
            "Epoch 341/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7744\n",
            "Epoch 342/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7744\n",
            "Epoch 343/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7744\n",
            "Epoch 344/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.7744\n",
            "Epoch 345/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.7744\n",
            "Epoch 346/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.7744\n",
            "Epoch 347/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5044 - accuracy: 0.7744\n",
            "Epoch 348/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.7744\n",
            "Epoch 349/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.7744\n",
            "Epoch 350/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5042 - accuracy: 0.7744\n",
            "Epoch 351/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5042 - accuracy: 0.7744\n",
            "Epoch 352/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7744\n",
            "Epoch 353/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.7744\n",
            "Epoch 354/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.7739\n",
            "Epoch 355/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5039 - accuracy: 0.7739\n",
            "Epoch 356/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5039 - accuracy: 0.7739\n",
            "Epoch 357/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7739\n",
            "Epoch 358/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.7739\n",
            "Epoch 359/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.7739\n",
            "Epoch 360/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7739\n",
            "Epoch 361/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7744\n",
            "Epoch 362/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7744\n",
            "Epoch 363/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7744\n",
            "Epoch 364/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7739\n",
            "Epoch 365/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7739\n",
            "Epoch 366/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7739\n",
            "Epoch 367/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5033 - accuracy: 0.7739\n",
            "Epoch 368/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7739\n",
            "Epoch 369/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7739\n",
            "Epoch 370/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5031 - accuracy: 0.7733\n",
            "Epoch 371/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5031 - accuracy: 0.7733\n",
            "Epoch 372/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.7733\n",
            "Epoch 373/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.7733\n",
            "Epoch 374/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5029 - accuracy: 0.7733\n",
            "Epoch 375/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5029 - accuracy: 0.7733\n",
            "Epoch 376/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7733\n",
            "Epoch 377/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7733\n",
            "Epoch 378/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.7733\n",
            "Epoch 379/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.7733\n",
            "Epoch 380/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5026 - accuracy: 0.7733\n",
            "Epoch 381/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5026 - accuracy: 0.7733\n",
            "Epoch 382/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.7733\n",
            "Epoch 383/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7733\n",
            "Epoch 384/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7733\n",
            "Epoch 385/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 0.7733\n",
            "Epoch 386/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5023 - accuracy: 0.7733\n",
            "Epoch 387/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5023 - accuracy: 0.7733\n",
            "Epoch 388/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7733\n",
            "Epoch 389/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.7733\n",
            "Epoch 390/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7733\n",
            "Epoch 391/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5021 - accuracy: 0.7733\n",
            "Epoch 392/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5021 - accuracy: 0.7733\n",
            "Epoch 393/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5020 - accuracy: 0.7733\n",
            "Epoch 394/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7733\n",
            "Epoch 395/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7733\n",
            "Epoch 396/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7733\n",
            "Epoch 397/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5018 - accuracy: 0.7733\n",
            "Epoch 398/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5018 - accuracy: 0.7728\n",
            "Epoch 399/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.7728\n",
            "Epoch 400/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7728\n",
            "Epoch 401/1000\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5017 - accuracy: 0.7728\n",
            "Epoch 402/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.7728\n",
            "Epoch 403/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.7728\n",
            "Epoch 404/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7728\n",
            "Epoch 405/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7728\n",
            "Epoch 406/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5014 - accuracy: 0.7728\n",
            "Epoch 407/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.7728\n",
            "Epoch 408/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5014 - accuracy: 0.7728\n",
            "Epoch 409/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5013 - accuracy: 0.7728\n",
            "Epoch 410/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5013 - accuracy: 0.7728\n",
            "Epoch 411/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7728\n",
            "Epoch 412/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7728\n",
            "Epoch 413/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7722\n",
            "Epoch 414/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.7722\n",
            "Epoch 415/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5011 - accuracy: 0.7717\n",
            "Epoch 416/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7717\n",
            "Epoch 417/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7717\n",
            "Epoch 418/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.7717\n",
            "Epoch 419/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5009 - accuracy: 0.7717\n",
            "Epoch 420/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5009 - accuracy: 0.7717\n",
            "Epoch 421/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.7717\n",
            "Epoch 422/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.7717\n",
            "Epoch 423/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.7717\n",
            "Epoch 424/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5007 - accuracy: 0.7717\n",
            "Epoch 425/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5007 - accuracy: 0.7717\n",
            "Epoch 426/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5007 - accuracy: 0.7717\n",
            "Epoch 427/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.7717\n",
            "Epoch 428/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.7711\n",
            "Epoch 429/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.7711\n",
            "Epoch 430/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.7711\n",
            "Epoch 431/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.7711\n",
            "Epoch 432/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.7711\n",
            "Epoch 433/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5004 - accuracy: 0.7711\n",
            "Epoch 434/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5004 - accuracy: 0.7711\n",
            "Epoch 435/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5003 - accuracy: 0.7711\n",
            "Epoch 436/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7711\n",
            "Epoch 437/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5003 - accuracy: 0.7711\n",
            "Epoch 438/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7711\n",
            "Epoch 439/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7711\n",
            "Epoch 440/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7711\n",
            "Epoch 441/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7711\n",
            "Epoch 442/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7706\n",
            "Epoch 443/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7706\n",
            "Epoch 444/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.7706\n",
            "Epoch 445/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.7706\n",
            "Epoch 446/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7706\n",
            "Epoch 447/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.7706\n",
            "Epoch 448/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7706\n",
            "Epoch 449/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.7706\n",
            "Epoch 450/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.7706\n",
            "Epoch 451/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.7711\n",
            "Epoch 452/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.7706\n",
            "Epoch 453/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4997 - accuracy: 0.7706\n",
            "Epoch 454/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4997 - accuracy: 0.7706\n",
            "Epoch 455/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4997 - accuracy: 0.7706\n",
            "Epoch 456/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4997 - accuracy: 0.7706\n",
            "Epoch 457/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7706\n",
            "Epoch 458/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4996 - accuracy: 0.7706\n",
            "Epoch 459/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4996 - accuracy: 0.7706\n",
            "Epoch 460/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7706\n",
            "Epoch 461/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7706\n",
            "Epoch 462/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7706\n",
            "Epoch 463/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7706\n",
            "Epoch 464/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4994 - accuracy: 0.7706\n",
            "Epoch 465/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4994 - accuracy: 0.7706\n",
            "Epoch 466/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7706\n",
            "Epoch 467/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7706\n",
            "Epoch 468/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7700\n",
            "Epoch 469/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7694\n",
            "Epoch 470/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7694\n",
            "Epoch 471/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7694\n",
            "Epoch 472/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.7694\n",
            "Epoch 473/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7694\n",
            "Epoch 474/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7694\n",
            "Epoch 475/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7700\n",
            "Epoch 476/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7700\n",
            "Epoch 477/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.7700\n",
            "Epoch 478/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7700\n",
            "Epoch 479/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7700\n",
            "Epoch 480/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7694\n",
            "Epoch 481/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7694\n",
            "Epoch 482/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7694\n",
            "Epoch 483/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7694\n",
            "Epoch 484/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7694\n",
            "Epoch 485/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.7694\n",
            "Epoch 486/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7694\n",
            "Epoch 487/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7694\n",
            "Epoch 488/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7694\n",
            "Epoch 489/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4987 - accuracy: 0.7694\n",
            "Epoch 490/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7694\n",
            "Epoch 491/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7694\n",
            "Epoch 492/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7694\n",
            "Epoch 493/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7694\n",
            "Epoch 494/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7694\n",
            "Epoch 495/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7694\n",
            "Epoch 496/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7694\n",
            "Epoch 497/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7694\n",
            "Epoch 498/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7694\n",
            "Epoch 499/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7694\n",
            "Epoch 500/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7694\n",
            "Epoch 501/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7694\n",
            "Epoch 502/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7694\n",
            "Epoch 503/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7694\n",
            "Epoch 504/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7694\n",
            "Epoch 505/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7694\n",
            "Epoch 506/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7694\n",
            "Epoch 507/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7694\n",
            "Epoch 508/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7694\n",
            "Epoch 509/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7694\n",
            "Epoch 510/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7694\n",
            "Epoch 511/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7694\n",
            "Epoch 512/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7694\n",
            "Epoch 513/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7694\n",
            "Epoch 514/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7694\n",
            "Epoch 515/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7694\n",
            "Epoch 516/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7694\n",
            "Epoch 517/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7694\n",
            "Epoch 518/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7694\n",
            "Epoch 519/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7694\n",
            "Epoch 520/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7694\n",
            "Epoch 521/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7694\n",
            "Epoch 522/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7694\n",
            "Epoch 523/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7694\n",
            "Epoch 524/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7694\n",
            "Epoch 525/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7694\n",
            "Epoch 526/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7689\n",
            "Epoch 527/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7689\n",
            "Epoch 528/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7689\n",
            "Epoch 529/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4978 - accuracy: 0.7689\n",
            "Epoch 530/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7689\n",
            "Epoch 531/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7689\n",
            "Epoch 532/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.7689\n",
            "Epoch 533/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.7689\n",
            "Epoch 534/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.7689\n",
            "Epoch 535/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.7689\n",
            "Epoch 536/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.7689\n",
            "Epoch 537/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7689\n",
            "Epoch 538/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7683\n",
            "Epoch 539/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7694\n",
            "Epoch 540/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7689\n",
            "Epoch 541/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.7689\n",
            "Epoch 542/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7689\n",
            "Epoch 543/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7689\n",
            "Epoch 544/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7689\n",
            "Epoch 545/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7694\n",
            "Epoch 546/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7694\n",
            "Epoch 547/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7694\n",
            "Epoch 548/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.7694\n",
            "Epoch 549/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7694\n",
            "Epoch 550/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.7694\n",
            "Epoch 551/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.7694\n",
            "Epoch 552/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.7694\n",
            "Epoch 553/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7694\n",
            "Epoch 554/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7694\n",
            "Epoch 555/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7694\n",
            "Epoch 556/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7694\n",
            "Epoch 557/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7694\n",
            "Epoch 558/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7694\n",
            "Epoch 559/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7694\n",
            "Epoch 560/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7694\n",
            "Epoch 561/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7694\n",
            "Epoch 562/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7694\n",
            "Epoch 563/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7694\n",
            "Epoch 564/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7694\n",
            "Epoch 565/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7694\n",
            "Epoch 566/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7694\n",
            "Epoch 567/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7694\n",
            "Epoch 568/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7694\n",
            "Epoch 569/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.7694\n",
            "Epoch 570/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7694\n",
            "Epoch 571/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7694\n",
            "Epoch 572/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7694\n",
            "Epoch 573/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7694\n",
            "Epoch 574/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7694\n",
            "Epoch 575/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7694\n",
            "Epoch 576/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7694\n",
            "Epoch 577/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7694\n",
            "Epoch 578/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7694\n",
            "Epoch 579/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7694\n",
            "Epoch 580/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7700\n",
            "Epoch 581/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7700\n",
            "Epoch 582/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7700\n",
            "Epoch 583/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7700\n",
            "Epoch 584/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7700\n",
            "Epoch 585/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7700\n",
            "Epoch 586/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7700\n",
            "Epoch 587/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7700\n",
            "Epoch 588/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7700\n",
            "Epoch 589/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7700\n",
            "Epoch 590/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7700\n",
            "Epoch 591/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7700\n",
            "Epoch 592/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7700\n",
            "Epoch 593/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7700\n",
            "Epoch 594/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7700\n",
            "Epoch 595/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4966 - accuracy: 0.7700\n",
            "Epoch 596/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7700\n",
            "Epoch 597/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7700\n",
            "Epoch 598/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7700\n",
            "Epoch 599/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7700\n",
            "Epoch 600/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7706\n",
            "Epoch 601/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7706\n",
            "Epoch 602/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7706\n",
            "Epoch 603/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7706\n",
            "Epoch 604/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7706\n",
            "Epoch 605/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7706\n",
            "Epoch 606/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7706\n",
            "Epoch 607/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7711\n",
            "Epoch 608/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7711\n",
            "Epoch 609/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.7711\n",
            "Epoch 610/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7711\n",
            "Epoch 611/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7711\n",
            "Epoch 612/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7711\n",
            "Epoch 613/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7711\n",
            "Epoch 614/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7711\n",
            "Epoch 615/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4963 - accuracy: 0.7711\n",
            "Epoch 616/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7711\n",
            "Epoch 617/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7711\n",
            "Epoch 618/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7711\n",
            "Epoch 619/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7711\n",
            "Epoch 620/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7711\n",
            "Epoch 621/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7711\n",
            "Epoch 622/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7711\n",
            "Epoch 623/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.7711\n",
            "Epoch 624/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.7711\n",
            "Epoch 625/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.7711\n",
            "Epoch 626/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.7711\n",
            "Epoch 627/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.7711\n",
            "Epoch 628/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7711\n",
            "Epoch 629/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.7711\n",
            "Epoch 630/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.7711\n",
            "Epoch 631/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.7711\n",
            "Epoch 632/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7711\n",
            "Epoch 633/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7706\n",
            "Epoch 634/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7706\n",
            "Epoch 635/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7706\n",
            "Epoch 636/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7706\n",
            "Epoch 637/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7706\n",
            "Epoch 638/1000\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4959 - accuracy: 0.7706\n",
            "Epoch 639/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7706\n",
            "Epoch 640/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7706\n",
            "Epoch 641/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7706\n",
            "Epoch 642/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7706\n",
            "Epoch 643/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7706\n",
            "Epoch 644/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7706\n",
            "Epoch 645/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4958 - accuracy: 0.7706\n",
            "Epoch 646/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7706\n",
            "Epoch 647/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7706\n",
            "Epoch 648/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7706\n",
            "Epoch 649/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.7706\n",
            "Epoch 650/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7706\n",
            "Epoch 651/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7706\n",
            "Epoch 652/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7706\n",
            "Epoch 653/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7706\n",
            "Epoch 654/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7706\n",
            "Epoch 655/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7706\n",
            "Epoch 656/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7706\n",
            "Epoch 657/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7706\n",
            "Epoch 658/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7706\n",
            "Epoch 659/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7706\n",
            "Epoch 660/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7706\n",
            "Epoch 661/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7706\n",
            "Epoch 662/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7706\n",
            "Epoch 663/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7706\n",
            "Epoch 664/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7706\n",
            "Epoch 665/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7706\n",
            "Epoch 666/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7706\n",
            "Epoch 667/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7706\n",
            "Epoch 668/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.7706\n",
            "Epoch 669/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7706\n",
            "Epoch 670/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7706\n",
            "Epoch 671/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7700\n",
            "Epoch 672/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.7700\n",
            "Epoch 673/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7700\n",
            "Epoch 674/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7700\n",
            "Epoch 675/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7700\n",
            "Epoch 676/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7700\n",
            "Epoch 677/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7700\n",
            "Epoch 678/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7700\n",
            "Epoch 679/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7700\n",
            "Epoch 680/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7700\n",
            "Epoch 681/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7700\n",
            "Epoch 682/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7700\n",
            "Epoch 683/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4952 - accuracy: 0.7700\n",
            "Epoch 684/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7700\n",
            "Epoch 685/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7700\n",
            "Epoch 686/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7700\n",
            "Epoch 687/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7700\n",
            "Epoch 688/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7700\n",
            "Epoch 689/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7700\n",
            "Epoch 690/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7700\n",
            "Epoch 691/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.7700\n",
            "Epoch 692/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7700\n",
            "Epoch 693/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7700\n",
            "Epoch 694/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7700\n",
            "Epoch 695/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7700\n",
            "Epoch 696/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7700\n",
            "Epoch 697/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7700\n",
            "Epoch 698/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7700\n",
            "Epoch 699/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7700\n",
            "Epoch 700/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7700\n",
            "Epoch 701/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7700\n",
            "Epoch 702/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7700\n",
            "Epoch 703/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7700\n",
            "Epoch 704/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7700\n",
            "Epoch 705/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.7700\n",
            "Epoch 706/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.7700\n",
            "Epoch 707/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7700\n",
            "Epoch 708/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7700\n",
            "Epoch 709/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7700\n",
            "Epoch 710/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7700\n",
            "Epoch 711/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7700\n",
            "Epoch 712/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.7700\n",
            "Epoch 713/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.7700\n",
            "Epoch 714/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7700\n",
            "Epoch 715/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.7700\n",
            "Epoch 716/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4947 - accuracy: 0.7700\n",
            "Epoch 717/1000\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4947 - accuracy: 0.7700\n",
            "Epoch 718/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7700\n",
            "Epoch 719/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.7700\n",
            "Epoch 720/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7700\n",
            "Epoch 721/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7700\n",
            "Epoch 722/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7700\n",
            "Epoch 723/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7700\n",
            "Epoch 724/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7700\n",
            "Epoch 725/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7700\n",
            "Epoch 726/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7700\n",
            "Epoch 727/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7700\n",
            "Epoch 728/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7700\n",
            "Epoch 729/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7700\n",
            "Epoch 730/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4945 - accuracy: 0.7700\n",
            "Epoch 731/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7700\n",
            "Epoch 732/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7700\n",
            "Epoch 733/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7700\n",
            "Epoch 734/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7700\n",
            "Epoch 735/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7700\n",
            "Epoch 736/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7700\n",
            "Epoch 737/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7700\n",
            "Epoch 738/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7700\n",
            "Epoch 739/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7700\n",
            "Epoch 740/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7700\n",
            "Epoch 741/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7700\n",
            "Epoch 742/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7700\n",
            "Epoch 743/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7700\n",
            "Epoch 744/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7700\n",
            "Epoch 745/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7700\n",
            "Epoch 746/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7694\n",
            "Epoch 747/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7694\n",
            "Epoch 748/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7694\n",
            "Epoch 749/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.7694\n",
            "Epoch 750/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7694\n",
            "Epoch 751/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7694\n",
            "Epoch 752/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7694\n",
            "Epoch 753/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7689\n",
            "Epoch 754/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7689\n",
            "Epoch 755/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7689\n",
            "Epoch 756/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7689\n",
            "Epoch 757/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.7689\n",
            "Epoch 758/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7689\n",
            "Epoch 759/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.7689\n",
            "Epoch 760/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7689\n",
            "Epoch 761/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7689\n",
            "Epoch 762/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7689\n",
            "Epoch 763/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7689\n",
            "Epoch 764/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7689\n",
            "Epoch 765/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7689\n",
            "Epoch 766/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7689\n",
            "Epoch 767/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7689\n",
            "Epoch 768/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7689\n",
            "Epoch 769/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7689\n",
            "Epoch 770/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7689\n",
            "Epoch 771/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7689\n",
            "Epoch 772/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7689\n",
            "Epoch 773/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7689\n",
            "Epoch 774/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7689\n",
            "Epoch 775/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7689\n",
            "Epoch 776/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7689\n",
            "Epoch 777/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7689\n",
            "Epoch 778/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7689\n",
            "Epoch 779/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7689\n",
            "Epoch 780/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7689\n",
            "Epoch 781/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7689\n",
            "Epoch 782/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7689\n",
            "Epoch 783/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7689\n",
            "Epoch 784/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7689\n",
            "Epoch 785/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7689\n",
            "Epoch 786/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7689\n",
            "Epoch 787/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7689\n",
            "Epoch 788/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7689\n",
            "Epoch 789/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7689\n",
            "Epoch 790/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7689\n",
            "Epoch 791/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7689\n",
            "Epoch 792/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7689\n",
            "Epoch 793/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7689\n",
            "Epoch 794/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7689\n",
            "Epoch 795/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7689\n",
            "Epoch 796/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7689\n",
            "Epoch 797/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7689\n",
            "Epoch 798/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7689\n",
            "Epoch 799/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7689\n",
            "Epoch 800/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7689\n",
            "Epoch 801/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7689\n",
            "Epoch 802/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4933 - accuracy: 0.7689\n",
            "Epoch 803/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7689\n",
            "Epoch 804/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7683\n",
            "Epoch 805/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7683\n",
            "Epoch 806/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7683\n",
            "Epoch 807/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7683\n",
            "Epoch 808/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7683\n",
            "Epoch 809/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.7683\n",
            "Epoch 810/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.7683\n",
            "Epoch 811/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.7683\n",
            "Epoch 812/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.7689\n",
            "Epoch 813/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.7683\n",
            "Epoch 814/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.7683\n",
            "Epoch 815/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7683\n",
            "Epoch 816/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7683\n",
            "Epoch 817/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7683\n",
            "Epoch 818/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.7689\n",
            "Epoch 819/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7689\n",
            "Epoch 820/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7689\n",
            "Epoch 821/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7689\n",
            "Epoch 822/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7689\n",
            "Epoch 823/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.7689\n",
            "Epoch 824/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7689\n",
            "Epoch 825/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.7689\n",
            "Epoch 826/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.7689\n",
            "Epoch 827/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.7689\n",
            "Epoch 828/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.7689\n",
            "Epoch 829/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.7689\n",
            "Epoch 830/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.7689\n",
            "Epoch 831/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.7689\n",
            "Epoch 832/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7694\n",
            "Epoch 833/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7694\n",
            "Epoch 834/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7694\n",
            "Epoch 835/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7694\n",
            "Epoch 836/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7694\n",
            "Epoch 837/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7694\n",
            "Epoch 838/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7694\n",
            "Epoch 839/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7694\n",
            "Epoch 840/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7694\n",
            "Epoch 841/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7694\n",
            "Epoch 842/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7694\n",
            "Epoch 843/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7694\n",
            "Epoch 844/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7694\n",
            "Epoch 845/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7694\n",
            "Epoch 846/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7694\n",
            "Epoch 847/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4922 - accuracy: 0.7694\n",
            "Epoch 848/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7694\n",
            "Epoch 849/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.7694\n",
            "Epoch 850/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.7694\n",
            "Epoch 851/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.7694\n",
            "Epoch 852/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7694\n",
            "Epoch 853/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7689\n",
            "Epoch 854/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7689\n",
            "Epoch 855/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7700\n",
            "Epoch 856/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7700\n",
            "Epoch 857/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7700\n",
            "Epoch 858/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7700\n",
            "Epoch 859/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7706\n",
            "Epoch 860/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7706\n",
            "Epoch 861/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4918 - accuracy: 0.7706\n",
            "Epoch 862/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7706\n",
            "Epoch 863/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7706\n",
            "Epoch 864/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7706\n",
            "Epoch 865/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4916 - accuracy: 0.7706\n",
            "Epoch 866/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4916 - accuracy: 0.7711\n",
            "Epoch 867/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4916 - accuracy: 0.7711\n",
            "Epoch 868/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4915 - accuracy: 0.7711\n",
            "Epoch 869/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4915 - accuracy: 0.7711\n",
            "Epoch 870/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4915 - accuracy: 0.7711\n",
            "Epoch 871/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.7711\n",
            "Epoch 872/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.7711\n",
            "Epoch 873/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.7711\n",
            "Epoch 874/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7711\n",
            "Epoch 875/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7711\n",
            "Epoch 876/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7711\n",
            "Epoch 877/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7711\n",
            "Epoch 878/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7711\n",
            "Epoch 879/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4911 - accuracy: 0.7711\n",
            "Epoch 880/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4911 - accuracy: 0.7706\n",
            "Epoch 881/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7700\n",
            "Epoch 882/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7700\n",
            "Epoch 883/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7700\n",
            "Epoch 884/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4909 - accuracy: 0.7706\n",
            "Epoch 885/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4909 - accuracy: 0.7706\n",
            "Epoch 886/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7706\n",
            "Epoch 887/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7706\n",
            "Epoch 888/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.7706\n",
            "Epoch 889/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7706\n",
            "Epoch 890/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7706\n",
            "Epoch 891/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7706\n",
            "Epoch 892/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7706\n",
            "Epoch 893/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7706\n",
            "Epoch 894/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.7706\n",
            "Epoch 895/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.7706\n",
            "Epoch 896/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.7700\n",
            "Epoch 897/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7700\n",
            "Epoch 898/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7700\n",
            "Epoch 899/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7700\n",
            "Epoch 900/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4903 - accuracy: 0.7700\n",
            "Epoch 901/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7700\n",
            "Epoch 902/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7700\n",
            "Epoch 903/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7700\n",
            "Epoch 904/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7700\n",
            "Epoch 905/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7700\n",
            "Epoch 906/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7700\n",
            "Epoch 907/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4900 - accuracy: 0.7700\n",
            "Epoch 908/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4900 - accuracy: 0.7700\n",
            "Epoch 909/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4900 - accuracy: 0.7700\n",
            "Epoch 910/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7700\n",
            "Epoch 911/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7700\n",
            "Epoch 912/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7700\n",
            "Epoch 913/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.7700\n",
            "Epoch 914/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.7700\n",
            "Epoch 915/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.7706\n",
            "Epoch 916/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.7700\n",
            "Epoch 917/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.7700\n",
            "Epoch 918/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7700\n",
            "Epoch 919/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7700\n",
            "Epoch 920/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7700\n",
            "Epoch 921/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7700\n",
            "Epoch 922/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7700\n",
            "Epoch 923/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7700\n",
            "Epoch 924/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7700\n",
            "Epoch 925/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7700\n",
            "Epoch 926/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7700\n",
            "Epoch 927/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4892 - accuracy: 0.7694\n",
            "Epoch 928/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4892 - accuracy: 0.7694\n",
            "Epoch 929/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4891 - accuracy: 0.7694\n",
            "Epoch 930/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7689\n",
            "Epoch 931/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4890 - accuracy: 0.7689\n",
            "Epoch 932/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.7694\n",
            "Epoch 933/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7694\n",
            "Epoch 934/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7694\n",
            "Epoch 935/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4888 - accuracy: 0.7689\n",
            "Epoch 936/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4888 - accuracy: 0.7683\n",
            "Epoch 937/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.7689\n",
            "Epoch 938/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7694\n",
            "Epoch 939/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7689\n",
            "Epoch 940/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4885 - accuracy: 0.7689\n",
            "Epoch 941/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4885 - accuracy: 0.7689\n",
            "Epoch 942/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.7689\n",
            "Epoch 943/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4884 - accuracy: 0.7689\n",
            "Epoch 944/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.7689\n",
            "Epoch 945/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.7689\n",
            "Epoch 946/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7689\n",
            "Epoch 947/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7694\n",
            "Epoch 948/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.7694\n",
            "Epoch 949/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.7694\n",
            "Epoch 950/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7694\n",
            "Epoch 951/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7694\n",
            "Epoch 952/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7689\n",
            "Epoch 953/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7689\n",
            "Epoch 954/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7683\n",
            "Epoch 955/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4878 - accuracy: 0.7683\n",
            "Epoch 956/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4878 - accuracy: 0.7689\n",
            "Epoch 957/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.7689\n",
            "Epoch 958/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.7689\n",
            "Epoch 959/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4876 - accuracy: 0.7689\n",
            "Epoch 960/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4876 - accuracy: 0.7689\n",
            "Epoch 961/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7689\n",
            "Epoch 962/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7689\n",
            "Epoch 963/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.7689\n",
            "Epoch 964/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7689\n",
            "Epoch 965/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.7683\n",
            "Epoch 966/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4873 - accuracy: 0.7683\n",
            "Epoch 967/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.7683\n",
            "Epoch 968/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.7683\n",
            "Epoch 969/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7683\n",
            "Epoch 970/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7683\n",
            "Epoch 971/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7683\n",
            "Epoch 972/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7683\n",
            "Epoch 973/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7683\n",
            "Epoch 974/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4869 - accuracy: 0.7683\n",
            "Epoch 975/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4869 - accuracy: 0.7683\n",
            "Epoch 976/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7683\n",
            "Epoch 977/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4868 - accuracy: 0.7689\n",
            "Epoch 978/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7689\n",
            "Epoch 979/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7689\n",
            "Epoch 980/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7689\n",
            "Epoch 981/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.7694\n",
            "Epoch 982/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7694\n",
            "Epoch 983/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.7694\n",
            "Epoch 984/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7694\n",
            "Epoch 985/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7694\n",
            "Epoch 986/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7694\n",
            "Epoch 987/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.7694\n",
            "Epoch 988/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.7694\n",
            "Epoch 989/1000\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.7694\n",
            "Epoch 990/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7694\n",
            "Epoch 991/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7694\n",
            "Epoch 992/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.7694\n",
            "Epoch 993/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.7700\n",
            "Epoch 994/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7689\n",
            "Epoch 995/1000\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4860 - accuracy: 0.7689\n",
            "Epoch 996/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7689\n",
            "Epoch 997/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7689\n",
            "Epoch 998/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7689\n",
            "Epoch 999/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7689\n",
            "Epoch 1000/1000\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2a7d810c40>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_y = model.predict(np.concatenate((X_test.numpy(),s1_test.reshape(-1,1).numpy()),axis=1))\n",
        "predicted_yy = (predicted_y > 0.5) * 1\n",
        "print('accuracy_score',accuracy_score(enc.transform(y_test.reshape(-1,1)).toarray(),predicted_yy)*100)\n",
        "print('classification_report\\n',classification_report(enc.transform(y_test.reshape(-1,1)).toarray(),predicted_yy))"
      ],
      "metadata": {
        "id": "t0zbqkyg5X3k",
        "outputId": "355386fe-e904-4fd3-d33e-fd2bbea12e78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 1ms/step\n",
            "accuracy_score 88.3\n",
            "classification_report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88       481\n",
            "           1       0.90      0.87      0.89       519\n",
            "\n",
            "   micro avg       0.88      0.88      0.88      1000\n",
            "   macro avg       0.88      0.88      0.88      1000\n",
            "weighted avg       0.88      0.88      0.88      1000\n",
            " samples avg       0.88      0.88      0.88      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pr_y_hat_1_z_0 = sum(predicted_yy[[i for i, x in enumerate(enc_s1_test[:,0]==0) if x],0]==1)\n",
        "Pr_y_hat_1_z_1 = sum(predicted_yy[[i for i, x in enumerate(enc_s1_test[:,0]==1) if x],0]==1)\n",
        "DI = min(Pr_y_hat_1_z_0, Pr_y_hat_1_z_1) / max(Pr_y_hat_1_z_0, Pr_y_hat_1_z_1)\n",
        "print('Disparate Impact', DI)"
      ],
      "metadata": {
        "id": "GV0mqAvM6E75",
        "outputId": "88330c50-6c63-46c2-9bff-c1b1f76fb49b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate Impact 0.23192019950124687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training with FR-Train"
      ],
      "metadata": {
        "id": "G-o0sd3O3L5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_tensors, val_tensors, test_tensors, train_opt, lambda_f, seed):\n",
        "    \"\"\"\n",
        "      Trains FR-Train by using the classes in FRTrain_arch.py.\n",
        "      \n",
        "      Args:\n",
        "        train_tensors: Training data.\n",
        "        val_tensors: Clean validation data.\n",
        "        test_tensors: Test data.\n",
        "        train_opt: Options for the training. It currently contains size of validation set, \n",
        "                number of epochs, generator/discriminator update ratio, and learning rates.\n",
        "        lambda_f: The tuning knob for L_2 (ref: FR-Train paper, Section 3.3).\n",
        "        #lambda_r: The tuning knob for L_3 (ref: FR-Train paper, Section 3.3).\n",
        "        seed: An integer value for specifying torch random seed.\n",
        "        \n",
        "      Returns:\n",
        "        Information about the tuning knobs (lambda_f, lambda_r),\n",
        "        the test accuracy of the trained model, and disparate impact of the trained model.\n",
        "    \"\"\"\n",
        "    \n",
        "    XS_train = train_tensors.XS_train\n",
        "    y_train = train_tensors.y_train\n",
        "    s1_train = train_tensors.s1_train\n",
        "    \n",
        "    XS_val = val_tensors.XS_val\n",
        "    y_val = val_tensors.y_val\n",
        "    s1_val = val_tensors.s1_val\n",
        "    \n",
        "    XS_test = test_tensors.XS_test\n",
        "    y_test = test_tensors.y_test\n",
        "    s1_test = test_tensors.s1_test\n",
        "    \n",
        "    # Saves return values here\n",
        "    test_result = [] \n",
        "    \n",
        "    val = train_opt.val # Number of data points in validation set\n",
        "    k = train_opt.k     # Update ratio of generator and discriminator (1:k training).\n",
        "    n_epochs = train_opt.n_epochs  # Number of training epoch\n",
        "    \n",
        "    # Changes the input validation data to an appropriate shape for the training\n",
        "    XSY_val = torch.cat([XS_val, y_val.reshape((y_val.shape[0], 1))], dim=1)  \n",
        "\n",
        "    # The loss values of each component will be saved in the following lists. \n",
        "    # We can draw epoch-loss graph by the following lists, if necessary.\n",
        "    g_losses =[]\n",
        "    d_f_losses = []\n",
        "    #d_r_losses = []\n",
        "    clean_test_result = []\n",
        "\n",
        "    bce_loss = torch.nn.BCELoss()\n",
        "\n",
        "    # Initializes generator and discriminator\n",
        "    generator = Generator()\n",
        "    discriminator_F = DiscriminatorF()\n",
        "    #discriminator_R = DiscriminatorR()\n",
        "\n",
        "    # Initializes weights\n",
        "    torch.manual_seed(seed)\n",
        "    generator.apply(weights_init_normal)\n",
        "    discriminator_F.apply(weights_init_normal)\n",
        "    #discriminator_R.apply(weights_init_normal)\n",
        "\n",
        "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=train_opt.lr_g)\n",
        "    optimizer_D_F = torch.optim.SGD(discriminator_F.parameters(), lr=train_opt.lr_f)\n",
        "    #optimizer_D_R = torch.optim.SGD(discriminator_R.parameters(), lr=train_opt.lr_r)\n",
        "\n",
        "    XSY_val_data = XSY_val[:val]\n",
        "\n",
        "    train_len = XS_train.shape[0]\n",
        "    val_len = XSY_val.shape[0]\n",
        "\n",
        "    # Ground truths using in Disriminator_R\n",
        "    Tensor = torch.FloatTensor\n",
        "    valid = Variable(Tensor(train_len, 1).fill_(1.0), requires_grad=False)\n",
        "    generated = Variable(Tensor(train_len, 1).fill_(0.0), requires_grad=False)\n",
        "    fake = Variable(Tensor(train_len, 1).fill_(0.0), requires_grad=False)\n",
        "    clean = Variable(Tensor(val_len, 1).fill_(1.0), requires_grad=False)\n",
        "    \n",
        "\n",
        "    #r_weight = torch.ones_like(y_train, requires_grad=False).float()\n",
        "    #r_ones = torch.ones_like(y_train, requires_grad=False).float()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # -------------------\n",
        "        #  Forwards Generator\n",
        "        # -------------------\n",
        "        if epoch % k == 0 or epoch < 500:\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "        gen_y = generator(XS_train).reshape(-1,1)\n",
        "        gen_data = torch.cat([XS_train, gen_y.reshape((gen_y.shape[0], 1))], dim=1)\n",
        "\n",
        "\n",
        "        # -------------------------------\n",
        "        #  Trains Fairness Discriminator\n",
        "        # -------------------------------\n",
        "\n",
        "        optimizer_D_F.zero_grad()\n",
        "        \n",
        "        # Discriminator_F tries to distinguish the sensitive groups by using the output of the generator.\n",
        "        d_f_loss = bce_loss(discriminator_F(gen_y.detach()), s1_train.reshape(-1,1))\n",
        "        d_f_loss.backward()\n",
        "        d_f_losses.append(d_f_loss)\n",
        "        optimizer_D_F.step()\n",
        "            \n",
        "            \n",
        "        # ---------------------------------\n",
        "        #  Trains Robustness Discriminator\n",
        "        # ---------------------------------\n",
        "        '''\n",
        "        optimizer_D_R.zero_grad()\n",
        "\n",
        "        # Discriminator_R tries to distinguish whether the input is from the validation data or the generated data from generator.\n",
        "        clean_loss =  bce_loss(discriminator_R(XSY_val_data), clean)\n",
        "        poison_loss = bce_loss(discriminator_R(gen_data.detach()), fake)\n",
        "        d_r_loss = 0.5 * (clean_loss + poison_loss)\n",
        "\n",
        "        d_r_loss.backward()\n",
        "        d_r_losses.append(d_r_loss)\n",
        "        optimizer_D_R.step()\n",
        "        '''\n",
        "        \n",
        "        # ---------------------\n",
        "        #  Updates Generator\n",
        "        # ---------------------\n",
        "\n",
        "\n",
        "        if epoch < 500 :\n",
        "            g_loss = 0.1 * bce_loss((F.tanh(gen_y)+1)/2, (y_train.reshape(-1,1)+1)/2)\n",
        "            g_loss.backward()\n",
        "            g_losses.append(g_loss)\n",
        "            optimizer_G.step()\n",
        "        elif epoch % k == 0:\n",
        "            #r_decision = discriminator_R(gen_data)\n",
        "            #r_gen = bce_loss(r_decision, generated)\n",
        "            \n",
        "            # ---------------------------------\n",
        "            #  Re-weights using output of D_R\n",
        "            # ---------------------------------\n",
        "            #if epoch % 100 == 0:\n",
        "            #    loss_ratio = (g_losses[-1]/d_r_losses[-1]).detach()\n",
        "            #    a = 1/(1+torch.exp(-(loss_ratio-3)))\n",
        "            #    b = 1-a\n",
        "            #    r_weight_tmp = r_decision.detach().squeeze()\n",
        "            #    r_weight = a * r_weight_tmp + b * r_ones\n",
        "\n",
        "            f_cost = F.binary_cross_entropy(discriminator_F(gen_y), s1_train.reshape(-1,1), reduction=\"none\").squeeze()\n",
        "            g_cost = F.binary_cross_entropy_with_logits(gen_y.squeeze(), (y_train.squeeze()+1)/2, reduction=\"none\").squeeze()\n",
        "\n",
        "            #f_gen = torch.mean(f_cost*r_weight)\n",
        "            f_gen = torch.mean(f_cost)\n",
        "            #g_loss = (1-lambda_f-lambda_r) * torch.mean(g_cost*r_weight) - lambda_f * f_gen -  lambda_r * r_gen \n",
        "            g_loss = (1-lambda_f) * torch.mean(g_cost) - lambda_f * f_gen \n",
        "\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "\n",
        "        g_losses.append(g_loss)\n",
        "\n",
        "        if epoch % 200 == 0:\n",
        "            print(\n",
        "                    \"[Lambda: %1f] [Epoch %d/%d] [D_F loss: %f] [G loss: %f]\"\n",
        "                    % (lambda_f, epoch, n_epochs, d_f_losses[-1], g_losses[-1])\n",
        "                )\n",
        "\n",
        "#     torch.save(generator.state_dict(), './FR-Train_on_poi_synthetic.pth')\n",
        "    tmp = test_model(generator, XS_test, y_test, s1_test)\n",
        "    test_result.append([lambda_f, tmp[0].item(), tmp[1]])\n",
        "\n",
        "    return test_result"
      ],
      "metadata": {
        "id": "DlaZAzey3Q4E"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = []\n",
        "train_tensors = Namespace(XS_train = XS_train, y_train = y_train, s1_train = s1_train)\n",
        "val_tensors = Namespace(XS_val = XS_val, y_val = y_val, s1_val = s1_val) \n",
        "test_tensors = Namespace(XS_test = XS_test, y_test = y_test, s1_test = s1_test)\n",
        "\n",
        "train_opt = Namespace(val=len(y_val), n_epochs=1000, k=5, lr_g=0.001, lr_f=0.001, lr_r=0.001)\n",
        "seed = 1\n",
        "\n",
        "lambda_f_set = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.52] # Lambda value for the fairness discriminator of FR-Train.\n",
        "#lambda_r = 0.4 # Lambda value for the robustness discriminator of FR-Train.\n",
        "\n",
        "for lambda_f in lambda_f_set:\n",
        "    train_result.append(train_model(train_tensors, val_tensors, test_tensors, train_opt, lambda_f = lambda_f, seed = seed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuacOLi93WAk",
        "outputId": "ed1f2c9c-a663-44e0-c9e5-92f319ef8e49"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Lambda: 0.100000] [Epoch 0/1000] [D_F loss: 0.686340] [G loss: 0.060358]\n",
            "[Lambda: 0.100000] [Epoch 200/1000] [D_F loss: 0.682480] [G loss: 0.057829]\n",
            "[Lambda: 0.100000] [Epoch 400/1000] [D_F loss: 0.679608] [G loss: 0.057678]\n",
            "[Lambda: 0.100000] [Epoch 600/1000] [D_F loss: 0.669466] [G loss: 0.456159]\n",
            "[Lambda: 0.100000] [Epoch 800/1000] [D_F loss: 0.666391] [G loss: 0.452935]\n",
            "Test accuracy: 0.8199999928474426\n",
            "P(y_hat=1 | z=0) = 0.283, P(y_hat=1 | z=1) = 0.527\n",
            "P(y_hat=1 | y=1, z=0) = 0.714, P(y_hat=1 | y=1, z=1) = 0.691\n",
            "Disparate Impact ratio = 0.537\n",
            "[Lambda: 0.150000] [Epoch 0/1000] [D_F loss: 0.686340] [G loss: 0.060358]\n",
            "[Lambda: 0.150000] [Epoch 200/1000] [D_F loss: 0.682480] [G loss: 0.057829]\n",
            "[Lambda: 0.150000] [Epoch 400/1000] [D_F loss: 0.679608] [G loss: 0.057678]\n",
            "[Lambda: 0.150000] [Epoch 600/1000] [D_F loss: 0.669815] [G loss: 0.393614]\n",
            "[Lambda: 0.150000] [Epoch 800/1000] [D_F loss: 0.667658] [G loss: 0.390722]\n",
            "Test accuracy: 0.8180000185966492\n",
            "P(y_hat=1 | z=0) = 0.286, P(y_hat=1 | z=1) = 0.522\n",
            "P(y_hat=1 | y=1, z=0) = 0.719, P(y_hat=1 | y=1, z=1) = 0.684\n",
            "Disparate Impact ratio = 0.548\n",
            "[Lambda: 0.200000] [Epoch 0/1000] [D_F loss: 0.686340] [G loss: 0.060358]\n",
            "[Lambda: 0.200000] [Epoch 200/1000] [D_F loss: 0.682480] [G loss: 0.057829]\n",
            "[Lambda: 0.200000] [Epoch 400/1000] [D_F loss: 0.679608] [G loss: 0.057678]\n",
            "[Lambda: 0.200000] [Epoch 600/1000] [D_F loss: 0.670144] [G loss: 0.331051]\n",
            "[Lambda: 0.200000] [Epoch 800/1000] [D_F loss: 0.668977] [G loss: 0.328410]\n",
            "Test accuracy: 0.8169999718666077\n",
            "P(y_hat=1 | z=0) = 0.293, P(y_hat=1 | z=1) = 0.520\n",
            "P(y_hat=1 | y=1, z=0) = 0.729, P(y_hat=1 | y=1, z=1) = 0.681\n",
            "Disparate Impact ratio = 0.564\n",
            "[Lambda: 0.250000] [Epoch 0/1000] [D_F loss: 0.686340] [G loss: 0.060358]\n",
            "[Lambda: 0.250000] [Epoch 200/1000] [D_F loss: 0.682480] [G loss: 0.057829]\n",
            "[Lambda: 0.250000] [Epoch 400/1000] [D_F loss: 0.679608] [G loss: 0.057678]\n",
            "[Lambda: 0.250000] [Epoch 600/1000] [D_F loss: 0.670463] [G loss: 0.268469]\n",
            "[Lambda: 0.250000] [Epoch 800/1000] [D_F loss: 0.670386] [G loss: 0.265995]\n",
            "Test accuracy: 0.8090000152587891\n",
            "P(y_hat=1 | z=0) = 0.297, P(y_hat=1 | z=1) = 0.506\n",
            "P(y_hat=1 | y=1, z=0) = 0.729, P(y_hat=1 | y=1, z=1) = 0.662\n",
            "Disparate Impact ratio = 0.587\n",
            "[Lambda: 0.300000] [Epoch 0/1000] [D_F loss: 0.686340] [G loss: 0.060358]\n",
            "[Lambda: 0.300000] [Epoch 200/1000] [D_F loss: 0.682480] [G loss: 0.057829]\n",
            "[Lambda: 0.300000] [Epoch 400/1000] [D_F loss: 0.679608] [G loss: 0.057678]\n",
            "[Lambda: 0.300000] [Epoch 600/1000] [D_F loss: 0.670785] [G loss: 0.205868]\n",
            "[Lambda: 0.300000] [Epoch 800/1000] [D_F loss: 0.671934] [G loss: 0.203469]\n",
            "Test accuracy: 0.8019999861717224\n",
            "P(y_hat=1 | z=0) = 0.297, P(y_hat=1 | z=1) = 0.489\n",
            "P(y_hat=1 | y=1, z=0) = 0.729, P(y_hat=1 | y=1, z=1) = 0.641\n",
            "Disparate Impact ratio = 0.606\n",
            "[Lambda: 0.350000] [Epoch 0/1000] [D_F loss: 0.686340] [G loss: 0.060358]\n",
            "[Lambda: 0.350000] [Epoch 200/1000] [D_F loss: 0.682480] [G loss: 0.057829]\n",
            "[Lambda: 0.350000] [Epoch 400/1000] [D_F loss: 0.679608] [G loss: 0.057678]\n",
            "[Lambda: 0.350000] [Epoch 600/1000] [D_F loss: 0.671136] [G loss: 0.143241]\n",
            "[Lambda: 0.350000] [Epoch 800/1000] [D_F loss: 0.673679] [G loss: 0.140822]\n",
            "Test accuracy: 0.7919999957084656\n",
            "P(y_hat=1 | z=0) = 0.305, P(y_hat=1 | z=1) = 0.473\n",
            "P(y_hat=1 | y=1, z=0) = 0.734, P(y_hat=1 | y=1, z=1) = 0.619\n",
            "Disparate Impact ratio = 0.646\n",
            "[Lambda: 0.400000] [Epoch 0/1000] [D_F loss: 0.686340] [G loss: 0.060358]\n",
            "[Lambda: 0.400000] [Epoch 200/1000] [D_F loss: 0.682480] [G loss: 0.057829]\n",
            "[Lambda: 0.400000] [Epoch 400/1000] [D_F loss: 0.679608] [G loss: 0.057678]\n",
            "[Lambda: 0.400000] [Epoch 600/1000] [D_F loss: 0.671563] [G loss: 0.080575]\n",
            "[Lambda: 0.400000] [Epoch 800/1000] [D_F loss: 0.675674] [G loss: 0.078037]\n",
            "Test accuracy: 0.7889999747276306\n",
            "P(y_hat=1 | z=0) = 0.316, P(y_hat=1 | z=1) = 0.466\n",
            "P(y_hat=1 | y=1, z=0) = 0.749, P(y_hat=1 | y=1, z=1) = 0.609\n",
            "Disparate Impact ratio = 0.678\n",
            "[Lambda: 0.450000] [Epoch 0/1000] [D_F loss: 0.686340] [G loss: 0.060358]\n",
            "[Lambda: 0.450000] [Epoch 200/1000] [D_F loss: 0.682480] [G loss: 0.057829]\n",
            "[Lambda: 0.450000] [Epoch 400/1000] [D_F loss: 0.679608] [G loss: 0.057678]\n",
            "[Lambda: 0.450000] [Epoch 600/1000] [D_F loss: 0.672155] [G loss: 0.017844]\n",
            "[Lambda: 0.450000] [Epoch 800/1000] [D_F loss: 0.677941] [G loss: 0.015085]\n",
            "Test accuracy: 0.7799999713897705\n",
            "P(y_hat=1 | z=0) = 0.326, P(y_hat=1 | z=1) = 0.454\n",
            "P(y_hat=1 | y=1, z=0) = 0.759, P(y_hat=1 | y=1, z=1) = 0.591\n",
            "Disparate Impact ratio = 0.718\n",
            "[Lambda: 0.520000] [Epoch 0/1000] [D_F loss: 0.686340] [G loss: 0.060358]\n",
            "[Lambda: 0.520000] [Epoch 200/1000] [D_F loss: 0.682480] [G loss: 0.057829]\n",
            "[Lambda: 0.520000] [Epoch 400/1000] [D_F loss: 0.679608] [G loss: 0.057678]\n",
            "[Lambda: 0.520000] [Epoch 600/1000] [D_F loss: 0.673651] [G loss: -0.070209]\n",
            "[Lambda: 0.520000] [Epoch 800/1000] [D_F loss: 0.681481] [G loss: -0.073399]\n",
            "Test accuracy: 0.7639999985694885\n",
            "P(y_hat=1 | z=0) = 0.330, P(y_hat=1 | z=1) = 0.426\n",
            "P(y_hat=1 | y=1, z=0) = 0.754, P(y_hat=1 | y=1, z=1) = 0.553\n",
            "Disparate Impact ratio = 0.774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tensors\n",
        "print(\"-----------------------------------------------------------------------------------\")\n",
        "print(\"------------------ Training Results of FR-Train on poisoned data ------------------\" )\n",
        "for i in range(len(train_result)):\n",
        "    print(\n",
        "        \"[Lambda_f: %.2f] Accuracy : %.3f, Disparate Impact : %.3f \"\n",
        "        % (train_result[i][0][0], train_result[i][0][1], train_result[i][0][2])\n",
        "    )       \n",
        "print(\"-----------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "a56Iwi2DAGMJ",
        "outputId": "520ae7e4-ce13-4126-c4cd-a3a4c74fffba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------------------\n",
            "------------------ Training Results of FR-Train on poisoned data ------------------\n",
            "[Lambda_f: 0.10] Accuracy : 0.820, Disparate Impact : 0.537 \n",
            "[Lambda_f: 0.15] Accuracy : 0.818, Disparate Impact : 0.548 \n",
            "[Lambda_f: 0.20] Accuracy : 0.817, Disparate Impact : 0.564 \n",
            "[Lambda_f: 0.25] Accuracy : 0.809, Disparate Impact : 0.587 \n",
            "[Lambda_f: 0.30] Accuracy : 0.802, Disparate Impact : 0.606 \n",
            "[Lambda_f: 0.35] Accuracy : 0.792, Disparate Impact : 0.646 \n",
            "[Lambda_f: 0.40] Accuracy : 0.789, Disparate Impact : 0.678 \n",
            "[Lambda_f: 0.45] Accuracy : 0.780, Disparate Impact : 0.718 \n",
            "[Lambda_f: 0.52] Accuracy : 0.764, Disparate Impact : 0.774 \n",
            "-----------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FSoUmuxpGTPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RF_train, Fairness discriminator ... "
      ],
      "metadata": {
        "id": "E9DB-0E6AgIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model2(train_tensors, val_tensors, test_tensors, train_opt, lambda_f, seed):\n",
        "    \"\"\"\n",
        "      Trains FR-Train by using the classes in FRTrain_arch.py.\n",
        "      \n",
        "      Args:\n",
        "        train_tensors: Training data.\n",
        "        val_tensors: Clean validation data.\n",
        "        test_tensors: Test data.\n",
        "        train_opt: Options for the training. It currently contains size of validation set, \n",
        "                number of epochs, generator/discriminator update ratio, and learning rates.\n",
        "        lambda_f: The tuning knob for L_2 (ref: FR-Train paper, Section 3.3).\n",
        "        #lambda_r: The tuning knob for L_3 (ref: FR-Train paper, Section 3.3).\n",
        "        seed: An integer value for specifying torch random seed.\n",
        "        \n",
        "      Returns:\n",
        "        Information about the tuning knobs (lambda_f, lambda_r),\n",
        "        the test accuracy of the trained model, and disparate impact of the trained model.\n",
        "    \"\"\"\n",
        "    \n",
        "    XS_train = train_tensors.XS_train\n",
        "    y_train = train_tensors.y_train\n",
        "    s1_train = train_tensors.s1_train\n",
        "    \n",
        "    XS_val = val_tensors.XS_val\n",
        "    y_val = val_tensors.y_val\n",
        "    s1_val = val_tensors.s1_val\n",
        "    \n",
        "    XS_test = test_tensors.XS_test\n",
        "    y_test = test_tensors.y_test\n",
        "    s1_test = test_tensors.s1_test\n",
        "    \n",
        "    # Saves return values here\n",
        "    test_result = [] \n",
        "    \n",
        "    val = train_opt.val # Number of data points in validation set\n",
        "    k = train_opt.k     # Update ratio of generator and discriminator (1:k training).\n",
        "    n_epochs = train_opt.n_epochs  # Number of training epoch\n",
        "    \n",
        "    # Changes the input validation data to an appropriate shape for the training\n",
        "    XSY_val = torch.cat([XS_val, y_val.reshape((y_val.shape[0], 1))], dim=1)  \n",
        "\n",
        "    # The loss values of each component will be saved in the following lists. \n",
        "    # We can draw epoch-loss graph by the following lists, if necessary.\n",
        "    g_losses =[]\n",
        "    #d_f_losses = []\n",
        "    #d_r_losses = []\n",
        "    clean_test_result = []\n",
        "\n",
        "    bce_loss = torch.nn.BCELoss()\n",
        "\n",
        "    # Initializes generator and discriminator\n",
        "    generator = Generator()\n",
        "    #discriminator_F = DiscriminatorF()\n",
        "    #discriminator_R = DiscriminatorR()\n",
        "\n",
        "    # Initializes weights\n",
        "    torch.manual_seed(seed)\n",
        "    generator.apply(weights_init_normal)\n",
        "    #discriminator_F.apply(weights_init_normal)\n",
        "    #discriminator_R.apply(weights_init_normal)\n",
        "\n",
        "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=train_opt.lr_g)\n",
        "    #optimizer_D_F = torch.optim.SGD(discriminator_F.parameters(), lr=train_opt.lr_f)\n",
        "    #optimizer_D_R = torch.optim.SGD(discriminator_R.parameters(), lr=train_opt.lr_r)\n",
        "\n",
        "    XSY_val_data = XSY_val[:val]\n",
        "\n",
        "    train_len = XS_train.shape[0]\n",
        "    val_len = XSY_val.shape[0]\n",
        "\n",
        "    # Ground truths using in Disriminator_R\n",
        "    Tensor = torch.FloatTensor\n",
        "    valid = Variable(Tensor(train_len, 1).fill_(1.0), requires_grad=False)\n",
        "    generated = Variable(Tensor(train_len, 1).fill_(0.0), requires_grad=False)\n",
        "    fake = Variable(Tensor(train_len, 1).fill_(0.0), requires_grad=False)\n",
        "    clean = Variable(Tensor(val_len, 1).fill_(1.0), requires_grad=False)\n",
        "    \n",
        "\n",
        "    #r_weight = torch.ones_like(y_train, requires_grad=False).float()\n",
        "    #r_ones = torch.ones_like(y_train, requires_grad=False).float()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # -------------------\n",
        "        #  Forwards Generator\n",
        "        # -------------------\n",
        "        if epoch % k == 0 or epoch < 500:\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "        gen_y = generator(XS_train).reshape(-1,1)\n",
        "        gen_data = torch.cat([XS_train, gen_y.reshape((gen_y.shape[0], 1))], dim=1)\n",
        "\n",
        "\n",
        "        # -------------------------------\n",
        "        #  Trains Fairness Discriminator\n",
        "        # -------------------------------\n",
        "        '''\n",
        "        optimizer_D_F.zero_grad()\n",
        "        \n",
        "        # Discriminator_F tries to distinguish the sensitive groups by using the output of the generator.\n",
        "        d_f_loss = bce_loss(discriminator_F(gen_y.detach()), s1_train.reshape(-1,1))\n",
        "        d_f_loss.backward()\n",
        "        d_f_losses.append(d_f_loss)\n",
        "        optimizer_D_F.step()\n",
        "        ''' \n",
        "            \n",
        "        # ---------------------------------\n",
        "        #  Trains Robustness Discriminator\n",
        "        # ---------------------------------\n",
        "        '''\n",
        "        optimizer_D_R.zero_grad()\n",
        "\n",
        "        # Discriminator_R tries to distinguish whether the input is from the validation data or the generated data from generator.\n",
        "        clean_loss =  bce_loss(discriminator_R(XSY_val_data), clean)\n",
        "        poison_loss = bce_loss(discriminator_R(gen_data.detach()), fake)\n",
        "        d_r_loss = 0.5 * (clean_loss + poison_loss)\n",
        "\n",
        "        d_r_loss.backward()\n",
        "        d_r_losses.append(d_r_loss)\n",
        "        optimizer_D_R.step()\n",
        "        '''\n",
        "        \n",
        "        # ---------------------\n",
        "        #  Updates Generator\n",
        "        # ---------------------\n",
        "\n",
        "\n",
        "        if epoch < 500 :\n",
        "            g_loss = 0.1 * bce_loss((F.tanh(gen_y)+1)/2, (y_train.reshape(-1,1)+1)/2)\n",
        "            g_loss.backward()\n",
        "            g_losses.append(g_loss)\n",
        "            optimizer_G.step()\n",
        "        elif epoch % k == 0:\n",
        "            #r_decision = discriminator_R(gen_data)\n",
        "            #r_gen = bce_loss(r_decision, generated)\n",
        "            \n",
        "            # ---------------------------------\n",
        "            #  Re-weights using output of D_R\n",
        "            # ---------------------------------\n",
        "            #if epoch % 100 == 0:\n",
        "            #    loss_ratio = (g_losses[-1]/d_r_losses[-1]).detach()\n",
        "            #    a = 1/(1+torch.exp(-(loss_ratio-3)))\n",
        "            #    b = 1-a\n",
        "            #    r_weight_tmp = r_decision.detach().squeeze()\n",
        "            #    r_weight = a * r_weight_tmp + b * r_ones\n",
        "\n",
        "            #f_cost = F.binary_cross_entropy(discriminator_F(gen_y), s1_train.reshape(-1,1), reduction=\"none\").squeeze()\n",
        "            g_cost = F.binary_cross_entropy_with_logits(gen_y.squeeze(), (y_train.squeeze()+1)/2, reduction=\"none\").squeeze()\n",
        "\n",
        "            #f_gen = torch.mean(f_cost*r_weight)\n",
        "            #f_gen = torch.mean(f_cost)\n",
        "            #g_loss = (1-lambda_f-lambda_r) * torch.mean(g_cost*r_weight) - lambda_f * f_gen -  lambda_r * r_gen \n",
        "            g_loss = (1-lambda_f) * torch.mean(g_cost) #- lambda_f * f_gen \n",
        "\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "\n",
        "        g_losses.append(g_loss)\n",
        "\n",
        "        if epoch % 200 == 0:\n",
        "            print(\n",
        "                    \"[Lambda: %1f] [Epoch %d/%d] [G loss: %f]\"\n",
        "                    % (lambda_f, epoch, n_epochs, g_losses[-1])\n",
        "                )\n",
        "\n",
        "#     torch.save(generator.state_dict(), './FR-Train_on_poi_synthetic.pth')\n",
        "    tmp = test_model(generator, XS_test, y_test, s1_test)\n",
        "    test_result.append([lambda_f, tmp[0].item(), tmp[1]])\n",
        "\n",
        "    return test_result"
      ],
      "metadata": {
        "id": "m7_DnvysApcA"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = []\n",
        "train_tensors = Namespace(XS_train = XS_train, y_train = y_train, s1_train = s1_train)\n",
        "val_tensors = Namespace(XS_val = XS_val, y_val = y_val, s1_val = s1_val) \n",
        "test_tensors = Namespace(XS_test = XS_test, y_test = y_test, s1_test = s1_test)\n",
        "\n",
        "train_opt = Namespace(val=len(y_val), n_epochs=1000, k=5, lr_g=0.001, lr_f=0.001, lr_r=0.001)\n",
        "seed = 1\n",
        "\n",
        "lambda_f_set = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.52] # Lambda value for the fairness discriminator of FR-Train.\n",
        "#lambda_r = 0.4 # Lambda value for the robustness discriminator of FR-Train.\n",
        "\n",
        "for lambda_f in lambda_f_set:\n",
        "    train_result.append(train_model2(train_tensors, val_tensors, test_tensors, train_opt, lambda_f = lambda_f, seed = seed))"
      ],
      "metadata": {
        "id": "XvJEa3IVBOpP",
        "outputId": "cc4463cc-d1a3-4e2b-9b00-1b7c48003a18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Lambda: 0.100000] [Epoch 0/1000] [G loss: 0.060358]\n",
            "[Lambda: 0.100000] [Epoch 200/1000] [G loss: 0.057829]\n",
            "[Lambda: 0.100000] [Epoch 400/1000] [G loss: 0.057678]\n",
            "[Lambda: 0.100000] [Epoch 600/1000] [G loss: 0.523154]\n",
            "[Lambda: 0.100000] [Epoch 800/1000] [G loss: 0.519407]\n",
            "Test accuracy: 0.8240000009536743\n",
            "P(y_hat=1 | z=0) = 0.272, P(y_hat=1 | z=1) = 0.541\n",
            "P(y_hat=1 | y=1, z=0) = 0.693, P(y_hat=1 | y=1, z=1) = 0.709\n",
            "Disparate Impact ratio = 0.503\n",
            "[Lambda: 0.150000] [Epoch 0/1000] [G loss: 0.060358]\n",
            "[Lambda: 0.150000] [Epoch 200/1000] [G loss: 0.057829]\n",
            "[Lambda: 0.150000] [Epoch 400/1000] [G loss: 0.057678]\n",
            "[Lambda: 0.150000] [Epoch 600/1000] [G loss: 0.494136]\n",
            "[Lambda: 0.150000] [Epoch 800/1000] [G loss: 0.490576]\n",
            "Test accuracy: 0.8230000138282776\n",
            "P(y_hat=1 | z=0) = 0.274, P(y_hat=1 | z=1) = 0.541\n",
            "P(y_hat=1 | y=1, z=0) = 0.693, P(y_hat=1 | y=1, z=1) = 0.709\n",
            "Disparate Impact ratio = 0.506\n",
            "[Lambda: 0.200000] [Epoch 0/1000] [G loss: 0.060358]\n",
            "[Lambda: 0.200000] [Epoch 200/1000] [G loss: 0.057829]\n",
            "[Lambda: 0.200000] [Epoch 400/1000] [G loss: 0.057678]\n",
            "[Lambda: 0.200000] [Epoch 600/1000] [G loss: 0.465117]\n",
            "[Lambda: 0.200000] [Epoch 800/1000] [G loss: 0.461746]\n",
            "Test accuracy: 0.8220000267028809\n",
            "P(y_hat=1 | z=0) = 0.276, P(y_hat=1 | z=1) = 0.541\n",
            "P(y_hat=1 | y=1, z=0) = 0.693, P(y_hat=1 | y=1, z=1) = 0.709\n",
            "Disparate Impact ratio = 0.510\n",
            "[Lambda: 0.250000] [Epoch 0/1000] [G loss: 0.060358]\n",
            "[Lambda: 0.250000] [Epoch 200/1000] [G loss: 0.057829]\n",
            "[Lambda: 0.250000] [Epoch 400/1000] [G loss: 0.057678]\n",
            "[Lambda: 0.250000] [Epoch 600/1000] [G loss: 0.436096]\n",
            "[Lambda: 0.250000] [Epoch 800/1000] [G loss: 0.432916]\n",
            "Test accuracy: 0.8220000267028809\n",
            "P(y_hat=1 | z=0) = 0.276, P(y_hat=1 | z=1) = 0.541\n",
            "P(y_hat=1 | y=1, z=0) = 0.693, P(y_hat=1 | y=1, z=1) = 0.709\n",
            "Disparate Impact ratio = 0.510\n",
            "[Lambda: 0.300000] [Epoch 0/1000] [G loss: 0.060358]\n",
            "[Lambda: 0.300000] [Epoch 200/1000] [G loss: 0.057829]\n",
            "[Lambda: 0.300000] [Epoch 400/1000] [G loss: 0.057678]\n",
            "[Lambda: 0.300000] [Epoch 600/1000] [G loss: 0.407072]\n",
            "[Lambda: 0.300000] [Epoch 800/1000] [G loss: 0.404087]\n",
            "Test accuracy: 0.8230000138282776\n",
            "P(y_hat=1 | z=0) = 0.277, P(y_hat=1 | z=1) = 0.541\n",
            "P(y_hat=1 | y=1, z=0) = 0.698, P(y_hat=1 | y=1, z=1) = 0.709\n",
            "Disparate Impact ratio = 0.513\n",
            "[Lambda: 0.350000] [Epoch 0/1000] [G loss: 0.060358]\n",
            "[Lambda: 0.350000] [Epoch 200/1000] [G loss: 0.057829]\n",
            "[Lambda: 0.350000] [Epoch 400/1000] [G loss: 0.057678]\n",
            "[Lambda: 0.350000] [Epoch 600/1000] [G loss: 0.378046]\n",
            "[Lambda: 0.350000] [Epoch 800/1000] [G loss: 0.375259]\n",
            "Test accuracy: 0.8230000138282776\n",
            "P(y_hat=1 | z=0) = 0.277, P(y_hat=1 | z=1) = 0.541\n",
            "P(y_hat=1 | y=1, z=0) = 0.698, P(y_hat=1 | y=1, z=1) = 0.709\n",
            "Disparate Impact ratio = 0.513\n",
            "[Lambda: 0.400000] [Epoch 0/1000] [G loss: 0.060358]\n",
            "[Lambda: 0.400000] [Epoch 200/1000] [G loss: 0.057829]\n",
            "[Lambda: 0.400000] [Epoch 400/1000] [G loss: 0.057678]\n",
            "[Lambda: 0.400000] [Epoch 600/1000] [G loss: 0.349018]\n",
            "[Lambda: 0.400000] [Epoch 800/1000] [G loss: 0.346432]\n",
            "Test accuracy: 0.8230000138282776\n",
            "P(y_hat=1 | z=0) = 0.277, P(y_hat=1 | z=1) = 0.541\n",
            "P(y_hat=1 | y=1, z=0) = 0.698, P(y_hat=1 | y=1, z=1) = 0.709\n",
            "Disparate Impact ratio = 0.513\n",
            "[Lambda: 0.450000] [Epoch 0/1000] [G loss: 0.060358]\n",
            "[Lambda: 0.450000] [Epoch 200/1000] [G loss: 0.057829]\n",
            "[Lambda: 0.450000] [Epoch 400/1000] [G loss: 0.057678]\n",
            "[Lambda: 0.450000] [Epoch 600/1000] [G loss: 0.319985]\n",
            "[Lambda: 0.450000] [Epoch 800/1000] [G loss: 0.317606]\n",
            "Test accuracy: 0.824999988079071\n",
            "P(y_hat=1 | z=0) = 0.281, P(y_hat=1 | z=1) = 0.541\n",
            "P(y_hat=1 | y=1, z=0) = 0.709, P(y_hat=1 | y=1, z=1) = 0.709\n",
            "Disparate Impact ratio = 0.519\n",
            "[Lambda: 0.520000] [Epoch 0/1000] [G loss: 0.060358]\n",
            "[Lambda: 0.520000] [Epoch 200/1000] [G loss: 0.057829]\n",
            "[Lambda: 0.520000] [Epoch 400/1000] [G loss: 0.057678]\n",
            "[Lambda: 0.520000] [Epoch 600/1000] [G loss: 0.279333]\n",
            "[Lambda: 0.520000] [Epoch 800/1000] [G loss: 0.277251]\n",
            "Test accuracy: 0.8270000219345093\n",
            "P(y_hat=1 | z=0) = 0.283, P(y_hat=1 | z=1) = 0.548\n",
            "P(y_hat=1 | y=1, z=0) = 0.714, P(y_hat=1 | y=1, z=1) = 0.716\n",
            "Disparate Impact ratio = 0.516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tensors\n",
        "print(\"-----------------------------------------------------------------------------------\")\n",
        "print(\"------------------ Training Results of FR-Train on poisoned data ------------------\" )\n",
        "for i in range(len(train_result)):\n",
        "    print(\n",
        "        \"[Lambda_f: %.2f] Accuracy : %.3f, Disparate Impact : %.3f \"\n",
        "        % (train_result[i][0][0], train_result[i][0][1], train_result[i][0][2])\n",
        "    )       \n",
        "print(\"-----------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "HOVNVMGuBZFa",
        "outputId": "01caa392-60d1-4082-f8fe-9ed800950c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------------------\n",
            "------------------ Training Results of FR-Train on poisoned data ------------------\n",
            "[Lambda_f: 0.10] Accuracy : 0.824, Disparate Impact : 0.503 \n",
            "[Lambda_f: 0.15] Accuracy : 0.823, Disparate Impact : 0.506 \n",
            "[Lambda_f: 0.20] Accuracy : 0.822, Disparate Impact : 0.510 \n",
            "[Lambda_f: 0.25] Accuracy : 0.822, Disparate Impact : 0.510 \n",
            "[Lambda_f: 0.30] Accuracy : 0.823, Disparate Impact : 0.513 \n",
            "[Lambda_f: 0.35] Accuracy : 0.823, Disparate Impact : 0.513 \n",
            "[Lambda_f: 0.40] Accuracy : 0.823, Disparate Impact : 0.513 \n",
            "[Lambda_f: 0.45] Accuracy : 0.825, Disparate Impact : 0.519 \n",
            "[Lambda_f: 0.52] Accuracy : 0.827, Disparate Impact : 0.516 \n",
            "-----------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}